{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 图像分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.2.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "print(\"PyTorch Version: \",torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义简单的ConvNet神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        '''\n",
    "         1：input channel\n",
    "         20：output channel\n",
    "         5： kernel size (单个数字时表示长宽相等的filter ，两个数字时分别表示长和宽)\n",
    "         1： stride （步长）\n",
    "        '''\n",
    "        self.conv1 = nn.Conv2d(1,20,5,1)\n",
    "        self.conv2 = nn.Conv2d(20,50,5,1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "         # x:1 * 28 * 28 -> 其中 1 指的是 channel 因为黑白的所以是 1 \n",
    "        x = F.relu(self.conv1(x)) # 20 * （28+1-5） * （28+1-5）--》 20 * 24 * 24\n",
    "        '''\n",
    "        max_pool2d()\n",
    "        x:input\n",
    "        2:kernel size\n",
    "        2:stride\n",
    "        '''\n",
    "        x = F.max_pool2d(x,2,2) # 使用的pooling size 是 2 所以 --》20 * 12 * 12\n",
    "        x = F.relu(self.conv2(x))# 50 * 12 * 12\n",
    "        x = F.max_pool2d(x,2,2) # 50 * 4 * 4\n",
    "        x = x.view(-1,4*4*50) # 将数据整合成二维的\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        y = F.log_softmax(x,dim =1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    for idx,(data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        pred = model(data) # batch_size * 10\n",
    "        ''' \n",
    "        torch.nn.functional.nll_loss(input, \n",
    "                                     target,\n",
    "                                     weight=None,\n",
    "                                     size_average=None,\n",
    "                                     ignore_index=-100,\n",
    "                                     reduce=None,\n",
    "                                     reduction='mean')\n",
    "        '''\n",
    "        loss = F.nll_loss(pred,target)\n",
    "        \n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx %100 ==0:\n",
    "            print(\"Train Epoch:{},iteration:{},Loss:{}\".format(epoch,idx,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.\n",
    "    correct = 0.\n",
    "    with torch.no_grad():\n",
    "        for idx,(data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            ''' loss 的 reduction 默认是 mean ：求解loss的平均值'''\n",
    "            total_loss += F.nll_loss(output,target,reduction=\"sum\")\n",
    "            pred = output.argmax(dim=1) #获取第一个维度的最大值的idx\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "        total_loss /= len(test_loader.dataset)\n",
    "        acc = correct /len(test_loader.dataset) * 100.\n",
    "        print(\"Test loss:{},Accracy:{}\".format(total_loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = datasets.MNIST(\"./mnist_data\",\n",
    "                            train = True,\n",
    "                            download = True,\n",
    "                            transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                            ])) # 如果路径下没有数据集会自动下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist data set 是 一个 dataset 包含多个方法使用 dir（mnist_data） 查看 mnist_data 的方法\n",
    "#dir(mnist_data)\n",
    "#mnist_data[2][0] #可以查看数据集的图片\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"./mnist_data\",\n",
    "                            train = True,\n",
    "                            download = True,\n",
    "                            transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                            ])),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 1,\n",
    "    pin_memory = True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"./mnist_data\",\n",
    "                            train = False,\n",
    "                            download = True,\n",
    "                            transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,),(0.3081,))\n",
    "                            ])),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 1,\n",
    "    pin_memory = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum = momentum)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:0,iteration:0,Loss:2.300945281982422\n",
      "Train Epoch:0,iteration:100,Loss:2.1642022132873535\n",
      "Train Epoch:0,iteration:200,Loss:0.8094296455383301\n",
      "Train Epoch:0,iteration:300,Loss:0.6092169880867004\n",
      "Train Epoch:0,iteration:400,Loss:0.43711647391319275\n",
      "Train Epoch:0,iteration:500,Loss:0.4811740815639496\n",
      "Train Epoch:0,iteration:600,Loss:0.31888359785079956\n",
      "Train Epoch:0,iteration:700,Loss:0.1649811863899231\n",
      "Train Epoch:0,iteration:800,Loss:0.29303786158561707\n",
      "Train Epoch:0,iteration:900,Loss:0.4696680009365082\n",
      "Train Epoch:0,iteration:1000,Loss:0.19931136071681976\n",
      "Train Epoch:0,iteration:1100,Loss:0.15847750008106232\n",
      "Train Epoch:0,iteration:1200,Loss:0.10180233418941498\n",
      "Train Epoch:0,iteration:1300,Loss:0.21272359788417816\n",
      "Train Epoch:0,iteration:1400,Loss:0.1466711461544037\n",
      "Train Epoch:0,iteration:1500,Loss:0.14425426721572876\n",
      "Train Epoch:0,iteration:1600,Loss:0.1450444906949997\n",
      "Train Epoch:0,iteration:1700,Loss:0.08176448941230774\n",
      "Train Epoch:0,iteration:1800,Loss:0.12413038313388824\n",
      "Test loss:0.18285374343395233,Accracy:96.39\n",
      "Train Epoch:1,iteration:0,Loss:0.2886589467525482\n",
      "Train Epoch:1,iteration:100,Loss:0.08972999453544617\n",
      "Train Epoch:1,iteration:200,Loss:0.05275024473667145\n",
      "Train Epoch:1,iteration:300,Loss:0.23874564468860626\n",
      "Train Epoch:1,iteration:400,Loss:0.07570407539606094\n",
      "Train Epoch:1,iteration:500,Loss:0.09509345889091492\n",
      "Train Epoch:1,iteration:600,Loss:0.027209430932998657\n",
      "Train Epoch:1,iteration:700,Loss:0.18676868081092834\n",
      "Train Epoch:1,iteration:800,Loss:0.116520956158638\n",
      "Train Epoch:1,iteration:900,Loss:0.07470700144767761\n",
      "Train Epoch:1,iteration:1000,Loss:0.0946870967745781\n",
      "Train Epoch:1,iteration:1100,Loss:0.10691305994987488\n",
      "Train Epoch:1,iteration:1200,Loss:0.012495636940002441\n",
      "Train Epoch:1,iteration:1300,Loss:0.11351671814918518\n",
      "Train Epoch:1,iteration:1400,Loss:0.062268197536468506\n",
      "Train Epoch:1,iteration:1500,Loss:0.012997031211853027\n",
      "Train Epoch:1,iteration:1600,Loss:0.03209950029850006\n",
      "Train Epoch:1,iteration:1700,Loss:0.0992351621389389\n",
      "Train Epoch:1,iteration:1800,Loss:0.045769765973091125\n",
      "Test loss:0.13461552560329437,Accracy:97.55\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train(model, device, train_dataloader, optimizer, epoch)\n",
    "    test(model, device, test_dataloader)\n",
    "    \n",
    "torch.save(model.state_dict(),\"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet -> AlexNet -> ResNet -> DanseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
