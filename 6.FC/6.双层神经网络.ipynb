{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么是 pythorch？\n",
    "他是一个基于python的科学计算库，有以下特点：\n",
    "-类似numpy，它可以使用GPU计算\n",
    "-可以用它来定义深度学习模型，可以灵活的进行深度学习模型的训练和使用\n",
    "\n",
    "### Tensors\n",
    "tensor类似于 numpy 的 ndarray 欸一的区别是 tensor 可以在gpu上加速训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个未初始化的 5x3 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个随机初始化的矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9623, 0.3378, 0.9717],\n",
       "        [0.5263, 0.1595, 0.6606],\n",
       "        [0.8230, 0.0130, 0.3258],\n",
       "        [0.3231, 0.8305, 0.3452],\n",
       "        [0.8249, 0.6772, 0.0222]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个全为 0 ，类型为 long 的矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(5,3,dtype = torch.long)\n",
    "y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从数据直接构建 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.3000, 3.0000, 4.0000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.3,3,4])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以从一个已有 tensor 构建一个 tensor。这是方法会重用原来 tensor 的特征，例如，数据类型，除非提供新的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.new_ones(5,3,dtype = torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4512, -0.7958,  0.3921],\n",
       "        [-1.2287,  0.9513,  0.8478],\n",
       "        [-0.5753,  0.2064,  0.4146],\n",
       "        [ 1.8651,  0.6105, -1.3129],\n",
       "        [ 0.4988,  0.4473, -0.8213]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn_like(x, dtype = torch.float) # 随机生成和 x 形状相同的矩阵，数据类型是 float\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到 tensor 的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "有很多 tensor 运算，我们先介绍加法运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4512,  0.2042,  1.3921],\n",
       "        [-0.2287,  1.9513,  1.8478],\n",
       "        [ 0.4247,  1.2064,  1.4146],\n",
       "        [ 2.8651,  1.6105, -0.3129],\n",
       "        [ 1.4988,  1.4473,  0.1787]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y # 矩阵内元素相加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种加法的写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4512,  0.2042,  1.3921],\n",
       "        [-0.2287,  1.9513,  1.8478],\n",
       "        [ 0.4247,  1.2064,  1.4146],\n",
       "        [ 2.8651,  1.6105, -0.3129],\n",
       "        [ 1.4988,  1.4473,  0.1787]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in-place 加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4512,  0.2042,  1.3921],\n",
       "        [-0.2287,  1.9513,  1.8478],\n",
       "        [ 0.4247,  1.2064,  1.4146],\n",
       "        [ 2.8651,  1.6105, -0.3129],\n",
       "        [ 1.4988,  1.4473,  0.1787]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x) # 下划线是将 x 的值加在 y 的身上。\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 任何 in-place 的运算都会以  _ 结尾。举例来说： x.cope_(y), x.t_() 会改变 x 的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各种类似 numpy 的indexing 都可以在 pytorch tensor 上面使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resizing: 如果你希望 resize/reshape 一个tensor， 可以使用 torch.view 操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4344,  0.8433,  0.1803,  0.9889, -1.4027,  1.7313,  1.0014,  0.3642],\n",
       "        [ 0.1604,  2.3526, -1.0215, -0.3110,  0.3864,  1.4276, -1.1543, -0.0125]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8) # 输入 -1 会自动帮助 整除 整个数组，不能是两个 -1 ，也不能是 -1 + 一个不能被整除的数\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 只有一个元素的 tensor 使用  .item() 方法可以把里面的 value 变成 python 的数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26488280296325684"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1)\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__idiv__',\n",
       " '__ilshift__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__long__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rfloordiv__',\n",
       " '__rmul__',\n",
       " '__rpow__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_backward_hooks',\n",
       " '_base',\n",
       " '_cdata',\n",
       " '_coalesced_',\n",
       " '_dimI',\n",
       " '_dimV',\n",
       " '_grad',\n",
       " '_grad_fn',\n",
       " '_indices',\n",
       " '_is_view',\n",
       " '_make_subclass',\n",
       " '_nnz',\n",
       " '_values',\n",
       " '_version',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'add',\n",
       " 'add_',\n",
       " 'addbmm',\n",
       " 'addbmm_',\n",
       " 'addcdiv',\n",
       " 'addcdiv_',\n",
       " 'addcmul',\n",
       " 'addcmul_',\n",
       " 'addmm',\n",
       " 'addmm_',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'addr_',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'any',\n",
       " 'apply_',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_strided',\n",
       " 'as_strided_',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan2_',\n",
       " 'atan_',\n",
       " 'backward',\n",
       " 'baddbmm',\n",
       " 'baddbmm_',\n",
       " 'bernoulli',\n",
       " 'bernoulli_',\n",
       " 'bfloat16',\n",
       " 'bincount',\n",
       " 'bitwise_not',\n",
       " 'bitwise_not_',\n",
       " 'bmm',\n",
       " 'bool',\n",
       " 'byte',\n",
       " 'cauchy_',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'char',\n",
       " 'cholesky',\n",
       " 'cholesky_inverse',\n",
       " 'cholesky_solve',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clamp_',\n",
       " 'clamp_max',\n",
       " 'clamp_max_',\n",
       " 'clamp_min',\n",
       " 'clamp_min_',\n",
       " 'clone',\n",
       " 'coalesce',\n",
       " 'contiguous',\n",
       " 'copy_',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'cpu',\n",
       " 'cross',\n",
       " 'cuda',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'data_ptr',\n",
       " 'dense_dim',\n",
       " 'dequantize',\n",
       " 'det',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_embed',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'digamma',\n",
       " 'digamma_',\n",
       " 'dim',\n",
       " 'dist',\n",
       " 'div',\n",
       " 'div_',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'eig',\n",
       " 'element_size',\n",
       " 'eq',\n",
       " 'eq_',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erf_',\n",
       " 'erfc',\n",
       " 'erfc_',\n",
       " 'erfinv',\n",
       " 'erfinv_',\n",
       " 'exp',\n",
       " 'exp_',\n",
       " 'expand',\n",
       " 'expand_as',\n",
       " 'expm1',\n",
       " 'expm1_',\n",
       " 'exponential_',\n",
       " 'fft',\n",
       " 'fill_',\n",
       " 'fill_diagonal_',\n",
       " 'flatten',\n",
       " 'flip',\n",
       " 'float',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'fmod',\n",
       " 'fmod_',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'gather',\n",
       " 'ge',\n",
       " 'ge_',\n",
       " 'gels',\n",
       " 'geometric_',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'get_device',\n",
       " 'grad',\n",
       " 'grad_fn',\n",
       " 'gt',\n",
       " 'gt_',\n",
       " 'half',\n",
       " 'hardshrink',\n",
       " 'histc',\n",
       " 'ifft',\n",
       " 'index_add',\n",
       " 'index_add_',\n",
       " 'index_copy',\n",
       " 'index_copy_',\n",
       " 'index_fill',\n",
       " 'index_fill_',\n",
       " 'index_put',\n",
       " 'index_put_',\n",
       " 'index_select',\n",
       " 'indices',\n",
       " 'int',\n",
       " 'int_repr',\n",
       " 'inverse',\n",
       " 'irfft',\n",
       " 'is_coalesced',\n",
       " 'is_complex',\n",
       " 'is_contiguous',\n",
       " 'is_cuda',\n",
       " 'is_distributed',\n",
       " 'is_floating_point',\n",
       " 'is_leaf',\n",
       " 'is_mkldnn',\n",
       " 'is_nonzero',\n",
       " 'is_pinned',\n",
       " 'is_quantized',\n",
       " 'is_same_size',\n",
       " 'is_set_to',\n",
       " 'is_shared',\n",
       " 'is_signed',\n",
       " 'is_sparse',\n",
       " 'isclose',\n",
       " 'item',\n",
       " 'kthvalue',\n",
       " 'layout',\n",
       " 'le',\n",
       " 'le_',\n",
       " 'lerp',\n",
       " 'lerp_',\n",
       " 'lgamma',\n",
       " 'lgamma_',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log10_',\n",
       " 'log1p',\n",
       " 'log1p_',\n",
       " 'log2',\n",
       " 'log2_',\n",
       " 'log_',\n",
       " 'log_normal_',\n",
       " 'log_softmax',\n",
       " 'logdet',\n",
       " 'logsumexp',\n",
       " 'long',\n",
       " 'lstsq',\n",
       " 'lt',\n",
       " 'lt_',\n",
       " 'lu',\n",
       " 'lu_solve',\n",
       " 'map2_',\n",
       " 'map_',\n",
       " 'masked_fill',\n",
       " 'masked_fill_',\n",
       " 'masked_scatter',\n",
       " 'masked_scatter_',\n",
       " 'masked_select',\n",
       " 'matmul',\n",
       " 'matrix_power',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'min',\n",
       " 'mm',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'mul_',\n",
       " 'multinomial',\n",
       " 'mv',\n",
       " 'mvlgamma',\n",
       " 'mvlgamma_',\n",
       " 'name',\n",
       " 'narrow',\n",
       " 'narrow_copy',\n",
       " 'ndim',\n",
       " 'ndimension',\n",
       " 'ne',\n",
       " 'ne_',\n",
       " 'neg',\n",
       " 'neg_',\n",
       " 'nelement',\n",
       " 'new',\n",
       " 'new_empty',\n",
       " 'new_full',\n",
       " 'new_ones',\n",
       " 'new_tensor',\n",
       " 'new_zeros',\n",
       " 'nonzero',\n",
       " 'norm',\n",
       " 'normal_',\n",
       " 'numel',\n",
       " 'numpy',\n",
       " 'orgqr',\n",
       " 'ormqr',\n",
       " 'output_nr',\n",
       " 'permute',\n",
       " 'pin_memory',\n",
       " 'pinverse',\n",
       " 'polygamma',\n",
       " 'polygamma_',\n",
       " 'pow',\n",
       " 'pow_',\n",
       " 'prelu',\n",
       " 'prod',\n",
       " 'put_',\n",
       " 'q_scale',\n",
       " 'q_zero_point',\n",
       " 'qr',\n",
       " 'qscheme',\n",
       " 'random_',\n",
       " 'reciprocal',\n",
       " 'reciprocal_',\n",
       " 'record_stream',\n",
       " 'register_hook',\n",
       " 'reinforce',\n",
       " 'relu',\n",
       " 'relu_',\n",
       " 'remainder',\n",
       " 'remainder_',\n",
       " 'renorm',\n",
       " 'renorm_',\n",
       " 'repeat',\n",
       " 'repeat_interleave',\n",
       " 'requires_grad',\n",
       " 'requires_grad_',\n",
       " 'reshape',\n",
       " 'reshape_as',\n",
       " 'resize',\n",
       " 'resize_',\n",
       " 'resize_as',\n",
       " 'resize_as_',\n",
       " 'retain_grad',\n",
       " 'rfft',\n",
       " 'roll',\n",
       " 'rot90',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'rsqrt',\n",
       " 'rsqrt_',\n",
       " 'scatter',\n",
       " 'scatter_',\n",
       " 'scatter_add',\n",
       " 'scatter_add_',\n",
       " 'select',\n",
       " 'set_',\n",
       " 'shape',\n",
       " 'share_memory_',\n",
       " 'short',\n",
       " 'sigmoid',\n",
       " 'sigmoid_',\n",
       " 'sign',\n",
       " 'sign_',\n",
       " 'sin',\n",
       " 'sin_',\n",
       " 'sinh',\n",
       " 'sinh_',\n",
       " 'size',\n",
       " 'slogdet',\n",
       " 'smm',\n",
       " 'softmax',\n",
       " 'solve',\n",
       " 'sort',\n",
       " 'sparse_dim',\n",
       " 'sparse_mask',\n",
       " 'sparse_resize_',\n",
       " 'sparse_resize_and_clear_',\n",
       " 'split',\n",
       " 'split_with_sizes',\n",
       " 'sqrt',\n",
       " 'sqrt_',\n",
       " 'squeeze',\n",
       " 'squeeze_',\n",
       " 'sspaddmm',\n",
       " 'std',\n",
       " 'stft',\n",
       " 'storage',\n",
       " 'storage_offset',\n",
       " 'storage_type',\n",
       " 'stride',\n",
       " 'sub',\n",
       " 'sub_',\n",
       " 'sum',\n",
       " 'sum_to_size',\n",
       " 'svd',\n",
       " 'symeig',\n",
       " 't',\n",
       " 't_',\n",
       " 'take',\n",
       " 'tan',\n",
       " 'tan_',\n",
       " 'tanh',\n",
       " 'tanh_',\n",
       " 'to',\n",
       " 'to_dense',\n",
       " 'to_mkldnn',\n",
       " 'to_sparse',\n",
       " 'tolist',\n",
       " 'topk',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'transpose_',\n",
       " 'triangular_solve',\n",
       " 'tril',\n",
       " 'tril_',\n",
       " 'triu',\n",
       " 'triu_',\n",
       " 'trunc',\n",
       " 'trunc_',\n",
       " 'type',\n",
       " 'type_as',\n",
       " 'unbind',\n",
       " 'unfold',\n",
       " 'uniform_',\n",
       " 'unique',\n",
       " 'unique_consecutive',\n",
       " 'unsqueeze',\n",
       " 'unsqueeze_',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'view_as',\n",
       " 'where',\n",
       " 'zero_']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 更多阅读\n",
    "各种 tensor operations ，包含transposing ， indexing ， slicing， mathematical operations， linear algebra， random numbers 在\n",
    " https://pythorch.org/docs/torch\n",
    " ### Numpy 和 Tensor 之间的转化\n",
    " 在 torch tensor 和 numpy array 之间相互转化 非常容易。\n",
    " <br>torch tensor 和 numpy array 会共享内存，所以改变其中的一项也会改变另一项。\n",
    " <br>把 torch tensor 转变成 numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改变 numpy array 里面的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]=2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 1., 1., 1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把 numpy array 转换成 torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a,1,out = a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=a+1   #  与 np.add(a,1,out = a)  a =a+1 会重新分配一个内存 a 将结果赋值给a ，而 out 方式 是直接修改 a 的值 ，使用 out 减少一次内存分配\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有 cpu 上的 tensor 都支撑转成 numpy 或者 从numpy 转成 tensor\n",
    "### CUDA Tensors\n",
    "使用 .to 方法，tensor 可以被移动到别的 device 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available() : # 用来检测是否可以使用 GPU 返回时时 bool 值\n",
    "    device = torch.device('cuda')\n",
    "    y = torch.ones_like(x , device = device) # 将tensor 转换到 gpu 上的方法\n",
    "    x = x.to(device)# 将tensor 转换到 gpu 上的方法\n",
    "    z = x+y\n",
    "    print (z)\n",
    "    print (z.to('cpu', torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.43441123,  0.84326065,  0.1803228 ,  0.988906  , -1.4026821 ,\n",
       "        1.731294  ,  1.0014081 ,  0.3641974 ,  0.16041838,  2.352633  ,\n",
       "       -1.0215448 , -0.31099698,  0.3863816 ,  1.4276028 , -1.1543412 ,\n",
       "       -0.01245503], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y.data.numpy() 如果 y 是 gpu 上的 tensor 是不能直接转换成 numpy 的，需要转换成 cpu\n",
    "y.to('cpu').data.numpy()\n",
    "y.cpu().data.numpy()\n",
    "# 因为 numpy 是在 cpu 上进行操作的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 热身：使用 numpy 实现两层神经网络\n",
    "一个全链接 relu 神经网络，一个隐藏层，没有bias，用来从 x 预测 y ，使用 L2 loss。\n",
    "<br>$$H = W_1 X + B_1$$\n",
    "$$A = MAX (0,H)（relu 函数）$$ \n",
    "$$Y_{HAT} = W_2 A + B_2$$\n",
    "<br>这一实现完全使用numpy来计算前向神经网络，loss，反向传播\n",
    "<br>numpy ndarray 是一个普通的 n 维 array。他不知道任何关于深度学习或者梯度（gradient）的知识，也不知道计算图（computation graph），指数一种用来计算数学运算的数据结构。\n",
    "<br>\n",
    "- forword pass\n",
    "- loss\n",
    "- backward pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 33687489.34997237\n",
      "1 33542260.44665605\n",
      "2 38379340.39463709\n",
      "3 41238441.098925695\n",
      "4 35869912.50237039\n",
      "5 23476027.640003655\n",
      "6 11877796.478465632\n",
      "7 5435913.439141745\n",
      "8 2729270.0457071587\n",
      "9 1669314.8531473358\n",
      "10 1208584.7037059148\n",
      "11 963207.6609149689\n",
      "12 803674.1233254061\n",
      "13 685516.762052031\n",
      "14 591834.4283323273\n",
      "15 514939.13524853217\n",
      "16 450682.4543652262\n",
      "17 396361.8885614187\n",
      "18 350038.11906894675\n",
      "19 310299.76885798445\n",
      "20 276032.0553690813\n",
      "21 246419.08090734377\n",
      "22 220670.6268977009\n",
      "23 198179.66758457018\n",
      "24 178452.2951206786\n",
      "25 161081.59239006968\n",
      "26 145741.77468304464\n",
      "27 132134.3433672666\n",
      "28 120074.75968869308\n",
      "29 109304.60865381814\n",
      "30 99664.55662869514\n",
      "31 91017.75760584822\n",
      "32 83245.92953941133\n",
      "33 76247.20511790381\n",
      "34 69933.86644799335\n",
      "35 64221.8649514855\n",
      "36 59048.92444471843\n",
      "37 54360.03183535926\n",
      "38 50101.554455209276\n",
      "39 46224.83120314304\n",
      "40 42692.0149911397\n",
      "41 39470.47824171583\n",
      "42 36528.38219472139\n",
      "43 33837.5168984889\n",
      "44 31374.454106446537\n",
      "45 29115.32112460379\n",
      "46 27040.391221870537\n",
      "47 25133.24401755058\n",
      "48 23378.758624375463\n",
      "49 21762.971256576693\n",
      "50 20273.959050493864\n",
      "51 18899.203568351717\n",
      "52 17630.751635322038\n",
      "53 16458.402590704318\n",
      "54 15374.083257106407\n",
      "55 14369.984033452452\n",
      "56 13439.50462946873\n",
      "57 12576.867046584914\n",
      "58 11776.03859717767\n",
      "59 11032.634887579994\n",
      "60 10341.704085877685\n",
      "61 9699.014287282582\n",
      "62 9101.241081501936\n",
      "63 8544.560849093517\n",
      "64 8026.9220792787855\n",
      "65 7545.349174883123\n",
      "66 7096.158045250045\n",
      "67 6676.459104229885\n",
      "68 6284.414094186502\n",
      "69 5918.002117506767\n",
      "70 5575.163668154433\n",
      "71 5254.370204812882\n",
      "72 4954.106401536057\n",
      "73 4672.801968245001\n",
      "74 4409.157955731164\n",
      "75 4161.969469977516\n",
      "76 3930.087102871698\n",
      "77 3712.4467697943383\n",
      "78 3508.123303675116\n",
      "79 3316.133811251472\n",
      "80 3135.703005720416\n",
      "81 2966.0178780684955\n",
      "82 2806.4123184721066\n",
      "83 2656.2655968101194\n",
      "84 2514.810679802811\n",
      "85 2381.6042337036215\n",
      "86 2256.1055735048167\n",
      "87 2137.7638001742453\n",
      "88 2026.2354398916507\n",
      "89 1921.025837991628\n",
      "90 1821.7428234737272\n",
      "91 1728.0294611253044\n",
      "92 1639.5332081098409\n",
      "93 1555.9547537279382\n",
      "94 1476.979231311446\n",
      "95 1402.3529259044496\n",
      "96 1331.788812885733\n",
      "97 1265.067190046413\n",
      "98 1201.955994162457\n",
      "99 1142.254304529606\n",
      "100 1085.7374377968986\n",
      "101 1032.2220839083493\n",
      "102 981.5451006425363\n",
      "103 933.5221648388665\n",
      "104 888.0445600657588\n",
      "105 844.9458742018248\n",
      "106 804.0748732452164\n",
      "107 765.3162515652826\n",
      "108 728.5682336592647\n",
      "109 693.695009396793\n",
      "110 660.6092896323408\n",
      "111 629.2156544322395\n",
      "112 599.4081200264518\n",
      "113 571.1037149152924\n",
      "114 544.2240992977272\n",
      "115 518.7250091010767\n",
      "116 494.4625470858751\n",
      "117 471.4062120914768\n",
      "118 449.49432269864747\n",
      "119 428.66940333509353\n",
      "120 408.8643813626153\n",
      "121 390.0297665327814\n",
      "122 372.11377122381066\n",
      "123 355.06962172249837\n",
      "124 338.85163667435756\n",
      "125 323.4240706380274\n",
      "126 308.7333436375016\n",
      "127 294.75173448421833\n",
      "128 281.4394581549127\n",
      "129 268.7703032114125\n",
      "130 256.7009491378402\n",
      "131 245.19843781274238\n",
      "132 234.24504481186176\n",
      "133 223.80114126330847\n",
      "134 213.84915226825157\n",
      "135 204.36329652948416\n",
      "136 195.3218268720538\n",
      "137 186.69951430630246\n",
      "138 178.47815789502852\n",
      "139 170.6383428148835\n",
      "140 163.15951779088863\n",
      "141 156.02604434029945\n",
      "142 149.2208064857838\n",
      "143 142.73443887641326\n",
      "144 136.5382416497833\n",
      "145 130.62311326613315\n",
      "146 124.97696031229248\n",
      "147 119.58698011554867\n",
      "148 114.4408358270324\n",
      "149 109.52651380151043\n",
      "150 104.83392923371908\n",
      "151 100.3515382802249\n",
      "152 96.06972386868244\n",
      "153 91.97940790666837\n",
      "154 88.07331938263204\n",
      "155 84.34203907023681\n",
      "156 80.77487690452173\n",
      "157 77.36377854640209\n",
      "158 74.10331925041717\n",
      "159 70.98666699057938\n",
      "160 68.00700328086234\n",
      "161 65.15871500820468\n",
      "162 62.43445436392743\n",
      "163 59.829726523853864\n",
      "164 57.340930218280036\n",
      "165 54.9596800009286\n",
      "166 52.68120866202638\n",
      "167 50.5032731764448\n",
      "168 48.418258748119925\n",
      "169 46.422374368536865\n",
      "170 44.51238307988112\n",
      "171 42.68441327609702\n",
      "172 40.93497238916185\n",
      "173 39.26053546614086\n",
      "174 37.65749384691968\n",
      "175 36.122202665508\n",
      "176 34.6521569925895\n",
      "177 33.244432333591995\n",
      "178 31.897285705517085\n",
      "179 30.60589511402263\n",
      "180 29.368897165322736\n",
      "181 28.183891566369834\n",
      "182 27.04920081984098\n",
      "183 25.96219671827857\n",
      "184 24.920047942846875\n",
      "185 23.921324743929446\n",
      "186 22.96442271242438\n",
      "187 22.047363886353317\n",
      "188 21.168864614273925\n",
      "189 20.326098445674358\n",
      "190 19.51826105010151\n",
      "191 18.74415280162517\n",
      "192 18.001730191614804\n",
      "193 17.289729357824797\n",
      "194 16.606899931105822\n",
      "195 15.95210534915631\n",
      "196 15.324089901618688\n",
      "197 14.722063796210609\n",
      "198 14.14440319551751\n",
      "199 13.590379913527237\n",
      "200 13.05878067158632\n",
      "201 12.54858314486556\n",
      "202 12.059210171018734\n",
      "203 11.589503580186367\n",
      "204 11.138758251761296\n",
      "205 10.706185131299492\n",
      "206 10.291327763064565\n",
      "207 9.893119224876784\n",
      "208 9.510569770140938\n",
      "209 9.143347201130364\n",
      "210 8.790818984651603\n",
      "211 8.452463148644588\n",
      "212 8.127592399770027\n",
      "213 7.815547677335147\n",
      "214 7.51620618637454\n",
      "215 7.228618967546906\n",
      "216 6.952236408718833\n",
      "217 6.686806386481174\n",
      "218 6.431853557238108\n",
      "219 6.186933107489573\n",
      "220 5.951684428942304\n",
      "221 5.7257727427814835\n",
      "222 5.5089412088316525\n",
      "223 5.30032682710985\n",
      "224 5.099864999808859\n",
      "225 4.907217269289107\n",
      "226 4.722073485110277\n",
      "227 4.544157043889754\n",
      "228 4.373180773877304\n",
      "229 4.208969374651219\n",
      "230 4.051078600334245\n",
      "231 3.899271981812551\n",
      "232 3.7532868496867966\n",
      "233 3.612932880756339\n",
      "234 3.477999486298956\n",
      "235 3.348303857351474\n",
      "236 3.2236347783249393\n",
      "237 3.103735422946963\n",
      "238 2.9883717640267387\n",
      "239 2.8774408682198453\n",
      "240 2.770771903519179\n",
      "241 2.668160235607542\n",
      "242 2.5695074804620988\n",
      "243 2.4746044463857646\n",
      "244 2.383293165416179\n",
      "245 2.295426714100814\n",
      "246 2.2109037300488765\n",
      "247 2.1295741628598117\n",
      "248 2.051361700791209\n",
      "249 1.9761074088173234\n",
      "250 1.903720015897742\n",
      "251 1.8339939878072014\n",
      "252 1.766899418678386\n",
      "253 1.7023217019398182\n",
      "254 1.6401835758117456\n",
      "255 1.5804155518774499\n",
      "256 1.5228766832401721\n",
      "257 1.4674599618675193\n",
      "258 1.4141073541302103\n",
      "259 1.3627676306111642\n",
      "260 1.31333088785466\n",
      "261 1.2657514692362395\n",
      "262 1.2199592713367056\n",
      "263 1.1758323768025754\n",
      "264 1.1333388912129096\n",
      "265 1.092424008367392\n",
      "266 1.0530333571017014\n",
      "267 1.0151152384237996\n",
      "268 0.9786000679169614\n",
      "269 0.9434147710703853\n",
      "270 0.909517697431353\n",
      "271 0.8768644750597595\n",
      "272 0.8454263998421785\n",
      "273 0.8151579047755366\n",
      "274 0.7859756909287892\n",
      "275 0.7578655571890962\n",
      "276 0.7307896486930242\n",
      "277 0.7047042681926017\n",
      "278 0.6795905487459636\n",
      "279 0.6553765358750684\n",
      "280 0.6320343118058982\n",
      "281 0.6095461782308522\n",
      "282 0.5878811791378123\n",
      "283 0.5670097592513357\n",
      "284 0.5469000606412417\n",
      "285 0.5275053518178502\n",
      "286 0.5088212392083992\n",
      "287 0.49080459698630385\n",
      "288 0.47345045950512166\n",
      "289 0.4567309549763994\n",
      "290 0.440597256691597\n",
      "291 0.4250458342678327\n",
      "292 0.410056506317679\n",
      "293 0.3956126406410993\n",
      "294 0.3816942105584193\n",
      "295 0.3682714996288503\n",
      "296 0.3553213076371412\n",
      "297 0.3428375640845489\n",
      "298 0.33080689093142807\n",
      "299 0.31920515876691824\n",
      "300 0.30801986541567494\n",
      "301 0.29722861549953256\n",
      "302 0.2868263319955741\n",
      "303 0.2767952284291333\n",
      "304 0.26712291263269583\n",
      "305 0.257797443270179\n",
      "306 0.2487976366590452\n",
      "307 0.2401204238835191\n",
      "308 0.23174819817176162\n",
      "309 0.22367375932804925\n",
      "310 0.21589217315499215\n",
      "311 0.20838327630173725\n",
      "312 0.20113764023418756\n",
      "313 0.19414865734234354\n",
      "314 0.187405681840803\n",
      "315 0.1809092326156626\n",
      "316 0.17463404619892672\n",
      "317 0.1685796638401395\n",
      "318 0.16273845527734263\n",
      "319 0.15710635893505248\n",
      "320 0.1516740230750515\n",
      "321 0.14643033444125736\n",
      "322 0.1413684871894033\n",
      "323 0.1364871533621294\n",
      "324 0.13177603305890928\n",
      "325 0.12723134668999703\n",
      "326 0.12284371303834066\n",
      "327 0.1186108705205887\n",
      "328 0.11452412093419295\n",
      "329 0.11058403277834652\n",
      "330 0.10678164471079729\n",
      "331 0.10310960491691888\n",
      "332 0.09956503711223838\n",
      "333 0.09614371578381341\n",
      "334 0.09284576972676008\n",
      "335 0.08965933939415122\n",
      "336 0.08658305827849083\n",
      "337 0.08361444450380111\n",
      "338 0.08075176407847076\n",
      "339 0.0779871391319564\n",
      "340 0.07531664241476962\n",
      "341 0.07273971748728451\n",
      "342 0.07025209211018263\n",
      "343 0.06785133127431131\n",
      "344 0.06553318321708691\n",
      "345 0.06329505291235615\n",
      "346 0.061134240582452454\n",
      "347 0.05904885538245451\n",
      "348 0.057036258816893226\n",
      "349 0.05509121831817348\n",
      "350 0.053213383862565564\n",
      "351 0.05140136075280058\n",
      "352 0.04965143984885442\n",
      "353 0.04796157670292259\n",
      "354 0.046329888881058046\n",
      "355 0.04475544836365278\n",
      "356 0.04323377928496562\n",
      "357 0.041765395814395506\n",
      "358 0.04034662115172424\n",
      "359 0.038976958470664375\n",
      "360 0.037653844727317774\n",
      "361 0.036376846188820575\n",
      "362 0.035143211059300634\n",
      "363 0.033952411230227214\n",
      "364 0.032801957546858204\n",
      "365 0.03169063617776913\n",
      "366 0.0306178382978273\n",
      "367 0.02958170088006365\n",
      "368 0.028580356674806965\n",
      "369 0.02761340939650092\n",
      "370 0.026680218014286362\n",
      "371 0.025778575261655664\n",
      "372 0.024907581888469796\n",
      "373 0.024066079074577446\n",
      "374 0.02325361414450699\n",
      "375 0.02246880352476553\n",
      "376 0.02171040129197504\n",
      "377 0.020977742598771002\n",
      "378 0.02027068353765302\n",
      "379 0.01958742580642587\n",
      "380 0.01892727484473968\n",
      "381 0.018289575151037355\n",
      "382 0.017673631101459746\n",
      "383 0.017078600297650952\n",
      "384 0.01650358337397003\n",
      "385 0.01594814393632488\n",
      "386 0.015411674674047852\n",
      "387 0.014893460545080141\n",
      "388 0.01439285546822834\n",
      "389 0.01390907310175895\n",
      "390 0.013441489624866758\n",
      "391 0.012990134104686173\n",
      "392 0.012553842663934542\n",
      "393 0.012132232383551794\n",
      "394 0.011724890098862427\n",
      "395 0.011331512957373401\n",
      "396 0.010951607337005552\n",
      "397 0.010584129826622555\n",
      "398 0.010229120805340311\n",
      "399 0.00988643381827438\n",
      "400 0.009554932848139044\n",
      "401 0.00923473946241038\n",
      "402 0.008925332006668028\n",
      "403 0.008626524167602536\n",
      "404 0.008337741595591216\n",
      "405 0.008058591696244573\n",
      "406 0.007788874618895351\n",
      "407 0.007528297915540559\n",
      "408 0.007276439556601771\n",
      "409 0.00703302789291985\n",
      "410 0.006797816037884247\n",
      "411 0.006570602697729884\n",
      "412 0.006351123127969334\n",
      "413 0.006138827821928197\n",
      "414 0.005933654887047385\n",
      "415 0.005735593869530007\n",
      "416 0.005543972541821582\n",
      "417 0.005358828037825614\n",
      "418 0.005179917771534159\n",
      "419 0.0050071229003257455\n",
      "420 0.004840048099626326\n",
      "421 0.004678577147032565\n",
      "422 0.0045225025839293765\n",
      "423 0.0043716893163117864\n",
      "424 0.0042259169700325505\n",
      "425 0.004085003800883559\n",
      "426 0.0039488315091669775\n",
      "427 0.0038172761720976518\n",
      "428 0.003690132215838338\n",
      "429 0.003567148045186727\n",
      "430 0.0034483700763160074\n",
      "431 0.0033335320434377588\n",
      "432 0.0032225081898164254\n",
      "433 0.003115216066364379\n",
      "434 0.0030115532111847916\n",
      "435 0.002911307538060606\n",
      "436 0.0028144854057775242\n",
      "437 0.0027208240038296824\n",
      "438 0.002630342431010322\n",
      "439 0.0025428585054257605\n",
      "440 0.0024582794162842283\n",
      "441 0.002376525776184103\n",
      "442 0.0022975630903398136\n",
      "443 0.0022211753852979252\n",
      "444 0.0021473687676454127\n",
      "445 0.0020760391318104063\n",
      "446 0.0020070594135799466\n",
      "447 0.0019403704256445134\n",
      "448 0.001875917457918438\n",
      "449 0.001813630152797049\n",
      "450 0.0017533955074930047\n",
      "451 0.0016951947615365273\n",
      "452 0.0016389181208090568\n",
      "453 0.0015845435270305324\n",
      "454 0.0015319449492856773\n",
      "455 0.0014810960848523234\n",
      "456 0.001431957592294849\n",
      "457 0.0013844598440773612\n",
      "458 0.0013385233286809203\n",
      "459 0.0012941377538525794\n",
      "460 0.001251240650393123\n",
      "461 0.0012097443999752233\n",
      "462 0.0011696324299377949\n",
      "463 0.0011308495972506363\n",
      "464 0.0010933787066381225\n",
      "465 0.0010571347793007575\n",
      "466 0.0010220910383385601\n",
      "467 0.0009882421405139619\n",
      "468 0.0009555058318607547\n",
      "469 0.0009238435105930642\n",
      "470 0.0008932411520000351\n",
      "471 0.0008636570923538224\n",
      "472 0.0008350551418666976\n",
      "473 0.0008073982043901365\n",
      "474 0.0007806569010764219\n",
      "475 0.0007548398659844983\n",
      "476 0.0007298411857385755\n",
      "477 0.0007056773359284198\n",
      "478 0.0006823277494960967\n",
      "479 0.0006597426973350003\n",
      "480 0.0006379098499849933\n",
      "481 0.0006167986986216202\n",
      "482 0.0005963996888348267\n",
      "483 0.0005766762067755315\n",
      "484 0.0005575943522846518\n",
      "485 0.0005391529544404686\n",
      "486 0.000521323852849892\n",
      "487 0.0005040782227794631\n",
      "488 0.0004874096000465971\n",
      "489 0.0004712969185726028\n",
      "490 0.0004557188826744272\n",
      "491 0.00044065259940023857\n",
      "492 0.00042608549959444376\n",
      "493 0.00041200709512993815\n",
      "494 0.0003983846343593202\n",
      "495 0.0003852174601443614\n",
      "496 0.00037249182477217094\n",
      "497 0.0003601802953907061\n",
      "498 0.0003482863194130782\n",
      "499 0.00033677870532594785\n"
     ]
    }
   ],
   "source": [
    "N , D_IN , H , D_OUT = 64 , 1000, 100, 10 # 64个数据，输入时1000维 隐层100维 输出是10维的\n",
    "# 随机创建一些训练数据\n",
    "x = np.random.randn(N,D_IN)\n",
    "y = np.random.randn(N,D_OUT)\n",
    "\n",
    "w1 = np.random.randn(D_IN,H)\n",
    "w2 = np.random.randn(H,D_OUT)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "#搭建神经网络并训练\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    h = x.dot(w1) # N * H  ---->  (N,D_IN) * (D_IN,H)  =  (N,H)\n",
    "    h_relu = np.maximum(h,0) # relu.\n",
    "    y_pred = h_relu.dot(w2) # N * D_OUT ---> (N,H) * (H,D_OUT) = (N,D_OUT) \n",
    "    \n",
    "    # Compute loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(it,loss)\n",
    "    \n",
    "    # Backwrad pass\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred) # H*D_OUT ---> H*N  *  N*D_OUT = H*D_OUT\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T) # N*H  ----> N*D_OUT  *  D_OUT*H\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    # updata weight of w1 and w2\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码解释\n",
    " - 1、grad_y_pred = 2.0 * (y_pred - y)\n",
    " - 2、grad_w2 = h_relu.T.dot(grad_y_pred) # H*D_OUT ---> H*N  *  N*D_OUT = H*D_OUT\n",
    " - 3、grad_h_relu = grad_y_pred.dot(w2.T) # N*H  ----> N*D_OUT  *  D_OUT*H\n",
    " - 4、grad_h = grad_h_relu.copy()\n",
    " - 5、grad_h[h<0] = 0\n",
    " - 6、grad_w1 = x.T.dot(grad_h)\n",
    " \n",
    " <br> 对于神经网络的前向计算过程可以看到是 \n",
    " $$h = w_1 * x$$\n",
    " $$h_{relu} = max(0,h)$$\n",
    " $$y_{pred} = w_2 * h_relu$$\n",
    " $$loss = (y_{pred}-y)^2$$\n",
    " <br> 所以当我们去求 w1 和 w2 的梯度的时候，要遵循链式求导法则\n",
    " $$\\frac{\\partial loss}{\\partial w_2} = \\frac{\\partial loss}{\\partial y_{pred}} * \\frac{\\partial y_{pred}}{\\partial w_2} $$\n",
    " 同理求解 $$\\frac{\\partial loss}{\\partial w_1} = \\frac{\\partial loss}{\\partial y_{pred}}* \\frac{\\partial y_{pred}}{\\partial h_{relu}} *\\frac{\\partial h_{relu}}{\\partial h }*\\frac{\\partial h}{\\partial w_1}$$\n",
    " \n",
    " <br><br> 关于 矩阵的转置 与 乘法 的前后位置，要根据 目标结果的矩阵结构进行调整。\n",
    " <br>比如 w_2 是 h*d_out 维度的 就需要h_relu进行转置得到结果 (H * N)  *  (N * D_OUT) = (H * D_OUT)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch： Tensors \n",
    "这次使用 Pytorch Tensors 来创建前向神经网络，计算损失，以及反向传播。\n",
    "<br>pytorch tensor 和 numpy ndarray 很像，最大的区别是 pytorch tensor 能在 CPU 或者 GPU 上计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28864868.0\n",
      "1 22573174.0\n",
      "2 20584410.0\n",
      "3 19761522.0\n",
      "4 18468640.0\n",
      "5 15900144.0\n",
      "6 12422999.0\n",
      "7 8836202.0\n",
      "8 5923798.5\n",
      "9 3866803.5\n",
      "10 2557826.75\n",
      "11 1753977.5\n",
      "12 1265576.5\n",
      "13 960247.625\n",
      "14 761581.375\n",
      "15 624680.5\n",
      "16 525131.125\n",
      "17 449207.15625\n",
      "18 389000.125\n",
      "19 339815.9375\n",
      "20 298826.3125\n",
      "21 264105.4375\n",
      "22 234405.734375\n",
      "23 208781.765625\n",
      "24 186493.3125\n",
      "25 167041.5625\n",
      "26 149981.890625\n",
      "27 134977.71875\n",
      "28 121737.6015625\n",
      "29 110006.9921875\n",
      "30 99580.28125\n",
      "31 90298.375\n",
      "32 82020.3984375\n",
      "33 74614.8828125\n",
      "34 67974.5\n",
      "35 62025.359375\n",
      "36 56670.66796875\n",
      "37 51846.3125\n",
      "38 47485.2109375\n",
      "39 43538.703125\n",
      "40 39969.4140625\n",
      "41 36730.125\n",
      "42 33788.68359375\n",
      "43 31116.11328125\n",
      "44 28682.1484375\n",
      "45 26460.5390625\n",
      "46 24431.5546875\n",
      "47 22576.76953125\n",
      "48 20878.40625\n",
      "49 19322.3984375\n",
      "50 17895.240234375\n",
      "51 16585.3984375\n",
      "52 15381.2333984375\n",
      "53 14273.6484375\n",
      "54 13255.1337890625\n",
      "55 12315.755859375\n",
      "56 11449.8701171875\n",
      "57 10650.81640625\n",
      "58 9913.349609375\n",
      "59 9231.18359375\n",
      "60 8600.138671875\n",
      "61 8016.17333984375\n",
      "62 7476.57763671875\n",
      "63 6977.0390625\n",
      "64 6513.67919921875\n",
      "65 6083.6669921875\n",
      "66 5684.52978515625\n",
      "67 5313.6748046875\n",
      "68 4969.13916015625\n",
      "69 4648.66162109375\n",
      "70 4350.4462890625\n",
      "71 4072.921142578125\n",
      "72 3814.361083984375\n",
      "73 3573.78173828125\n",
      "74 3349.11962890625\n",
      "75 3139.5234375\n",
      "76 2944.05322265625\n",
      "77 2761.665283203125\n",
      "78 2591.27978515625\n",
      "79 2432.150146484375\n",
      "80 2283.4609375\n",
      "81 2144.44140625\n",
      "82 2014.4456787109375\n",
      "83 1892.771240234375\n",
      "84 1778.958251953125\n",
      "85 1672.37548828125\n",
      "86 1572.5657958984375\n",
      "87 1479.083984375\n",
      "88 1391.498046875\n",
      "89 1309.475830078125\n",
      "90 1232.7032470703125\n",
      "91 1160.7308349609375\n",
      "92 1093.2110595703125\n",
      "93 1029.78173828125\n",
      "94 970.218994140625\n",
      "95 914.288330078125\n",
      "96 861.7329711914062\n",
      "97 812.357666015625\n",
      "98 765.9688110351562\n",
      "99 722.3709716796875\n",
      "100 681.3369140625\n",
      "101 642.7498779296875\n",
      "102 606.4594116210938\n",
      "103 572.30419921875\n",
      "104 540.1776733398438\n",
      "105 509.92913818359375\n",
      "106 481.4573669433594\n",
      "107 454.650634765625\n",
      "108 429.3855895996094\n",
      "109 405.5863037109375\n",
      "110 383.1785888671875\n",
      "111 362.0456848144531\n",
      "112 342.1297607421875\n",
      "113 323.3487854003906\n",
      "114 305.6523742675781\n",
      "115 288.9594421386719\n",
      "116 273.21124267578125\n",
      "117 258.34893798828125\n",
      "118 244.33401489257812\n",
      "119 231.11106872558594\n",
      "120 218.62496948242188\n",
      "121 206.84561157226562\n",
      "122 195.71725463867188\n",
      "123 185.20657348632812\n",
      "124 175.2861328125\n",
      "125 165.91712951660156\n",
      "126 157.06097412109375\n",
      "127 148.70306396484375\n",
      "128 140.80308532714844\n",
      "129 133.3334503173828\n",
      "130 126.2736587524414\n",
      "131 119.59947204589844\n",
      "132 113.29542541503906\n",
      "133 107.3335189819336\n",
      "134 101.69174194335938\n",
      "135 96.3602294921875\n",
      "136 91.31352233886719\n",
      "137 86.53950500488281\n",
      "138 82.02527618408203\n",
      "139 77.75344848632812\n",
      "140 73.70890045166016\n",
      "141 69.88861083984375\n",
      "142 66.26949310302734\n",
      "143 62.84373092651367\n",
      "144 59.60118103027344\n",
      "145 56.53191375732422\n",
      "146 53.6234245300293\n",
      "147 50.87123489379883\n",
      "148 48.26396179199219\n",
      "149 45.793182373046875\n",
      "150 43.45273971557617\n",
      "151 41.23478698730469\n",
      "152 39.13380813598633\n",
      "153 37.14384078979492\n",
      "154 35.25830078125\n",
      "155 33.46992492675781\n",
      "156 31.775428771972656\n",
      "157 30.1690731048584\n",
      "158 28.646202087402344\n",
      "159 27.202831268310547\n",
      "160 25.834308624267578\n",
      "161 24.53629493713379\n",
      "162 23.303918838500977\n",
      "163 22.136436462402344\n",
      "164 21.028160095214844\n",
      "165 19.977869033813477\n",
      "166 18.981172561645508\n",
      "167 18.034717559814453\n",
      "168 17.137239456176758\n",
      "169 16.286067962646484\n",
      "170 15.47805404663086\n",
      "171 14.711223602294922\n",
      "172 13.982650756835938\n",
      "173 13.291097640991211\n",
      "174 12.63516616821289\n",
      "175 12.01268196105957\n",
      "176 11.421134948730469\n",
      "177 10.859527587890625\n",
      "178 10.326125144958496\n",
      "179 9.81960678100586\n",
      "180 9.338407516479492\n",
      "181 8.88199234008789\n",
      "182 8.447888374328613\n",
      "183 8.035658836364746\n",
      "184 7.643893241882324\n",
      "185 7.271697998046875\n",
      "186 6.918018341064453\n",
      "187 6.582180976867676\n",
      "188 6.262979984283447\n",
      "189 5.959585666656494\n",
      "190 5.671277046203613\n",
      "191 5.396786212921143\n",
      "192 5.136463642120361\n",
      "193 4.888742446899414\n",
      "194 4.6530561447143555\n",
      "195 4.429126739501953\n",
      "196 4.216530799865723\n",
      "197 4.0142669677734375\n",
      "198 3.8217499256134033\n",
      "199 3.638411283493042\n",
      "200 3.464200496673584\n",
      "201 3.298581123352051\n",
      "202 3.141380548477173\n",
      "203 2.991406202316284\n",
      "204 2.849133253097534\n",
      "205 2.7134900093078613\n",
      "206 2.5845985412597656\n",
      "207 2.4620020389556885\n",
      "208 2.344942569732666\n",
      "209 2.233961820602417\n",
      "210 2.128225564956665\n",
      "211 2.027517795562744\n",
      "212 1.9317700862884521\n",
      "213 1.8406329154968262\n",
      "214 1.7540044784545898\n",
      "215 1.671138048171997\n",
      "216 1.5926271677017212\n",
      "217 1.5176701545715332\n",
      "218 1.4463164806365967\n",
      "219 1.3785333633422852\n",
      "220 1.3139656782150269\n",
      "221 1.2524285316467285\n",
      "222 1.1939852237701416\n",
      "223 1.1381468772888184\n",
      "224 1.0850224494934082\n",
      "225 1.0344589948654175\n",
      "226 0.9861932992935181\n",
      "227 0.9402456283569336\n",
      "228 0.8964971303939819\n",
      "229 0.8549154996871948\n",
      "230 0.8151779770851135\n",
      "231 0.7775344848632812\n",
      "232 0.7413935661315918\n",
      "233 0.707116425037384\n",
      "234 0.6743337512016296\n",
      "235 0.6432391405105591\n",
      "236 0.6135159134864807\n",
      "237 0.5853103399276733\n",
      "238 0.5582645535469055\n",
      "239 0.5325965881347656\n",
      "240 0.5080881118774414\n",
      "241 0.4846823215484619\n",
      "242 0.4623781442642212\n",
      "243 0.4412452280521393\n",
      "244 0.4209677577018738\n",
      "245 0.4017108678817749\n",
      "246 0.38339078426361084\n",
      "247 0.365792453289032\n",
      "248 0.34912335872650146\n",
      "249 0.3331919312477112\n",
      "250 0.31795811653137207\n",
      "251 0.30344322323799133\n",
      "252 0.28966084122657776\n",
      "253 0.27649426460266113\n",
      "254 0.26389139890670776\n",
      "255 0.25188159942626953\n",
      "256 0.24045640230178833\n",
      "257 0.22957326471805573\n",
      "258 0.21923403441905975\n",
      "259 0.20929096639156342\n",
      "260 0.19980990886688232\n",
      "261 0.19077369570732117\n",
      "262 0.18212731182575226\n",
      "263 0.17384721338748932\n",
      "264 0.1660962849855423\n",
      "265 0.15860499441623688\n",
      "266 0.1514464169740677\n",
      "267 0.14465051889419556\n",
      "268 0.1381041705608368\n",
      "269 0.13191759586334229\n",
      "270 0.1260005086660385\n",
      "271 0.1203424334526062\n",
      "272 0.11494942009449005\n",
      "273 0.10978487133979797\n",
      "274 0.10487227886915207\n",
      "275 0.10017403215169907\n",
      "276 0.09575007855892181\n",
      "277 0.09145296365022659\n",
      "278 0.08737485110759735\n",
      "279 0.08348288387060165\n",
      "280 0.0797664076089859\n",
      "281 0.07621712237596512\n",
      "282 0.07284460961818695\n",
      "283 0.06958406418561935\n",
      "284 0.06649096310138702\n",
      "285 0.06354395300149918\n",
      "286 0.0607110895216465\n",
      "287 0.05803778022527695\n",
      "288 0.055463407188653946\n",
      "289 0.05302590876817703\n",
      "290 0.05066539719700813\n",
      "291 0.048418931663036346\n",
      "292 0.04626665636897087\n",
      "293 0.04425395652651787\n",
      "294 0.04229867085814476\n",
      "295 0.04043465852737427\n",
      "296 0.03866618871688843\n",
      "297 0.03697245568037033\n",
      "298 0.03535337746143341\n",
      "299 0.03378508239984512\n",
      "300 0.03230686113238335\n",
      "301 0.0309031680226326\n",
      "302 0.029548246413469315\n",
      "303 0.02824893593788147\n",
      "304 0.02703077159821987\n",
      "305 0.025855932384729385\n",
      "306 0.02472412958741188\n",
      "307 0.02363695204257965\n",
      "308 0.022624440491199493\n",
      "309 0.021649006754159927\n",
      "310 0.020713195204734802\n",
      "311 0.01982390694320202\n",
      "312 0.01896311528980732\n",
      "313 0.018147559836506844\n",
      "314 0.01735958829522133\n",
      "315 0.01661083847284317\n",
      "316 0.015897443518042564\n",
      "317 0.01522209495306015\n",
      "318 0.01455796416848898\n",
      "319 0.013943728990852833\n",
      "320 0.013348105363547802\n",
      "321 0.012787122279405594\n",
      "322 0.012245619669556618\n",
      "323 0.011719164438545704\n",
      "324 0.011222196742892265\n",
      "325 0.010747781954705715\n",
      "326 0.010289976373314857\n",
      "327 0.009860617108643055\n",
      "328 0.00944508332759142\n",
      "329 0.009049017913639545\n",
      "330 0.008673177100718021\n",
      "331 0.008315778337419033\n",
      "332 0.007973735220730305\n",
      "333 0.007640978787094355\n",
      "334 0.007325600832700729\n",
      "335 0.007021583151072264\n",
      "336 0.006733493879437447\n",
      "337 0.006461690180003643\n",
      "338 0.006193473469465971\n",
      "339 0.0059427558444440365\n",
      "340 0.005697641987353563\n",
      "341 0.005469249561429024\n",
      "342 0.005253123585134745\n",
      "343 0.005038673058152199\n",
      "344 0.004833230283111334\n",
      "345 0.004641448147594929\n",
      "346 0.004460352472960949\n",
      "347 0.004281893372535706\n",
      "348 0.004113948903977871\n",
      "349 0.003954105544835329\n",
      "350 0.0038008091505616903\n",
      "351 0.0036509993951767683\n",
      "352 0.0035070825833827257\n",
      "353 0.003368905046954751\n",
      "354 0.003239444922655821\n",
      "355 0.003119897563010454\n",
      "356 0.0030007190071046352\n",
      "357 0.002884799847379327\n",
      "358 0.002779655857011676\n",
      "359 0.0026714131236076355\n",
      "360 0.002574402838945389\n",
      "361 0.0024733615573495626\n",
      "362 0.00238570524379611\n",
      "363 0.002299167448654771\n",
      "364 0.0022164902184158564\n",
      "365 0.0021356253419071436\n",
      "366 0.0020634287502616644\n",
      "367 0.0019834167324006557\n",
      "368 0.001913070329464972\n",
      "369 0.0018465364119037986\n",
      "370 0.001779981073923409\n",
      "371 0.001718921703286469\n",
      "372 0.001655556377954781\n",
      "373 0.0016016603913158178\n",
      "374 0.001545222126878798\n",
      "375 0.0014898721128702164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376 0.0014393437886610627\n",
      "377 0.0013920152559876442\n",
      "378 0.00134615832939744\n",
      "379 0.001302773249335587\n",
      "380 0.0012598922476172447\n",
      "381 0.0012197219766676426\n",
      "382 0.0011777495965361595\n",
      "383 0.0011410013539716601\n",
      "384 0.0011045736027881503\n",
      "385 0.0010687587782740593\n",
      "386 0.0010351547971367836\n",
      "387 0.0010039608459919691\n",
      "388 0.0009727043798193336\n",
      "389 0.0009419703274033964\n",
      "390 0.0009147454402409494\n",
      "391 0.0008859812514856458\n",
      "392 0.0008582376758567989\n",
      "393 0.0008319890475831926\n",
      "394 0.0008084892178885639\n",
      "395 0.0007854024297557771\n",
      "396 0.0007619785610586405\n",
      "397 0.000739160634111613\n",
      "398 0.0007183004636317492\n",
      "399 0.0006991305272094905\n",
      "400 0.0006783369462937117\n",
      "401 0.000658962584566325\n",
      "402 0.0006404792657122016\n",
      "403 0.0006223366362974048\n",
      "404 0.0006051096133887768\n",
      "405 0.0005881002289243042\n",
      "406 0.0005724950460717082\n",
      "407 0.0005580248543992639\n",
      "408 0.0005416653002612293\n",
      "409 0.0005262998165562749\n",
      "410 0.0005132630467414856\n",
      "411 0.0004995333729311824\n",
      "412 0.00048626665375195444\n",
      "413 0.00047466036630794406\n",
      "414 0.000461360439658165\n",
      "415 0.000450414780061692\n",
      "416 0.00043914385605603456\n",
      "417 0.0004279573040548712\n",
      "418 0.0004178590315859765\n",
      "419 0.00040723811252973974\n",
      "420 0.00039713692967779934\n",
      "421 0.0003870452055707574\n",
      "422 0.0003776845696847886\n",
      "423 0.00036940269637852907\n",
      "424 0.00036041514249518514\n",
      "425 0.00035245789331384003\n",
      "426 0.0003440086729824543\n",
      "427 0.00033618827001191676\n",
      "428 0.00032886501867324114\n",
      "429 0.0003218187775928527\n",
      "430 0.0003143145004287362\n",
      "431 0.0003073632251471281\n",
      "432 0.00029895984334871173\n",
      "433 0.00029200027347542346\n",
      "434 0.00028722305432893336\n",
      "435 0.0002801715163514018\n",
      "436 0.00027294637402519584\n",
      "437 0.0002678201417438686\n",
      "438 0.0002616868878249079\n",
      "439 0.00025641490356065333\n",
      "440 0.0002510792692191899\n",
      "441 0.00024594718706794083\n",
      "442 0.00024046865291893482\n",
      "443 0.00023592468642164022\n",
      "444 0.00023070175666362047\n",
      "445 0.00022647209698334336\n",
      "446 0.0002217085857409984\n",
      "447 0.0002171966334572062\n",
      "448 0.00021260509674903005\n",
      "449 0.00020800776837859303\n",
      "450 0.00020445491827558726\n",
      "451 0.0002004071866394952\n",
      "452 0.00019676382362376899\n",
      "453 0.000192673149285838\n",
      "454 0.00018856108363252133\n",
      "455 0.00018491208902560174\n",
      "456 0.0001814130082493648\n",
      "457 0.00017817760817706585\n",
      "458 0.0001753974356688559\n",
      "459 0.00017172562365885824\n",
      "460 0.00016834527195896953\n",
      "461 0.00016488911933265626\n",
      "462 0.00016247549501713365\n",
      "463 0.000158983952132985\n",
      "464 0.00015618868928868324\n",
      "465 0.000153257860802114\n",
      "466 0.00015049193461891264\n",
      "467 0.00014738641039002687\n",
      "468 0.0001450009149266407\n",
      "469 0.0001428511895937845\n",
      "470 0.00014044986164662987\n",
      "471 0.00013836276775691658\n",
      "472 0.00013503555965144187\n",
      "473 0.00013319951540324837\n",
      "474 0.00013084032980259508\n",
      "475 0.00012876882101409137\n",
      "476 0.0001265246537514031\n",
      "477 0.00012446050823200494\n",
      "478 0.00012251075531821698\n",
      "479 0.00012078681902494282\n",
      "480 0.00011883357365150005\n",
      "481 0.00011698387243086472\n",
      "482 0.00011526410526130348\n",
      "483 0.00011312036804156378\n",
      "484 0.00011096421076217666\n",
      "485 0.00010954738536383957\n",
      "486 0.00010780050797620788\n",
      "487 0.00010612783080432564\n",
      "488 0.0001042775038513355\n",
      "489 0.00010280788410454988\n",
      "490 0.00010176315845455974\n",
      "491 9.981227049138397e-05\n",
      "492 9.848282934399322e-05\n",
      "493 9.714331827126443e-05\n",
      "494 9.57925440161489e-05\n",
      "495 9.42787155508995e-05\n",
      "496 9.280485392082483e-05\n",
      "497 9.164631774183363e-05\n",
      "498 9.042644524015486e-05\n",
      "499 8.928069291869178e-05\n"
     ]
    }
   ],
   "source": [
    "N , D_IN , H , D_OUT = 64 , 1000, 100, 10 # 64个数据，输入时1000维 隐层100维 输出是10维的\n",
    "# 随机创建一些训练数据\n",
    "x = torch.randn(N,D_IN) # x = np.random.randn(N,D_IN)\n",
    "y = torch.randn(N,D_OUT) # y = np.random.randn(N,D_OUT)\n",
    "\n",
    "w1 = torch.randn(D_IN,H) # w1 = np.random.randn(D_IN,H)\n",
    "w2 = torch.randn(H,D_OUT) # w2 = np.random.randn(H,D_OUT)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "#搭建神经网络并训练\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    h = x.mm(w1)   # h = x.dot(w1) # N * H  ---->  (N,D_IN) * (D_IN,H)  =  (N,H)\n",
    "    h_relu = h.clamp(min=0) # clamp 是取上下限，可以设定上下限，或单独设置上限或者下限 #h_relu = np.maximum(h,0) # relu.\n",
    "    y_pred = h_relu.mm(w2) #y_pred = h_relu.dot(w2) # N * D_OUT ---> (N,H) * (H,D_OUT) = (N,D_OUT) \n",
    "    \n",
    "    # Compute loss\n",
    "    #loss = np.square(y_pred - y).sum()\n",
    "    loss = (y_pred - y).pow(2).sum().item() # pow(2) 是计算2次方， item（） 是将 一个值的tensor 转换为 数字 \n",
    "    print(it,loss)\n",
    "    \n",
    "    # Backwrad pass\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    \n",
    "    #grad_w2 = h_relu.T.dot(grad_y_pred) # H*D_OUT ---> H*N  *  N*D_OUT = H*D_OUT\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)# pytorch 中 transform 是使用 .t()\n",
    "    \n",
    "    #grad_h_relu = grad_y_pred.dot(w2.T) # N*H  ----> N*D_OUT  *  D_OUT*H\n",
    "    grad_h_relu = grad_y_pred.mm(w2.T)\n",
    "    \n",
    "    #grad_h = grad_h_relu.copy()\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    \n",
    "    grad_h[h<0] = 0\n",
    "    \n",
    "    #grad_w1 = x.T.dot(grad_h)\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "    \n",
    "    # updata weight of w1 and w2\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensor 自带的自动计算梯度的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.,requires_grad = True) \n",
    "w = torch.tensor(2.,requires_grad = True) \n",
    "b = torch.tensor(3.,requires_grad = True)\n",
    "# 定义 tensor 的时候对于需要计算梯度的 tensor 要提前声明 requires_grad  = True\n",
    "y = w*x + b\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 将 上面的简单的神经网路 用自动计算梯度的方式重现一遍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26895730.0\n",
      "1 21270212.0\n",
      "2 20549032.0\n",
      "3 21628784.0\n",
      "4 22527788.0\n",
      "5 21438294.0\n",
      "6 18021872.0\n",
      "7 13128427.0\n",
      "8 8546938.0\n",
      "9 5161103.0\n",
      "10 3063709.75\n",
      "11 1861585.875\n",
      "12 1196805.25\n",
      "13 823660.4375\n",
      "14 606331.5\n",
      "15 471772.03125\n",
      "16 382574.59375\n",
      "17 319282.6875\n",
      "18 271721.5\n",
      "19 234352.109375\n",
      "20 204014.15625\n",
      "21 178833.53125\n",
      "22 157589.96875\n",
      "23 139467.875\n",
      "24 123868.5390625\n",
      "25 110383.609375\n",
      "26 98670.9921875\n",
      "27 88450.3125\n",
      "28 79475.359375\n",
      "29 71565.296875\n",
      "30 64575.48046875\n",
      "31 58381.3203125\n",
      "32 52875.8046875\n",
      "33 47975.5234375\n",
      "34 43599.42578125\n",
      "35 39682.44921875\n",
      "36 36166.59375\n",
      "37 33006.2265625\n",
      "38 30160.912109375\n",
      "39 27593.416015625\n",
      "40 25272.05859375\n",
      "41 23170.716796875\n",
      "42 21265.34765625\n",
      "43 19534.841796875\n",
      "44 17961.2578125\n",
      "45 16528.984375\n",
      "46 15223.50390625\n",
      "47 14032.513671875\n",
      "48 12946.642578125\n",
      "49 11952.9453125\n",
      "50 11043.064453125\n",
      "51 10208.759765625\n",
      "52 9443.271484375\n",
      "53 8741.6708984375\n",
      "54 8096.90869140625\n",
      "55 7503.69677734375\n",
      "56 6957.56787109375\n",
      "57 6454.23974609375\n",
      "58 5990.2470703125\n",
      "59 5562.08203125\n",
      "60 5166.89892578125\n",
      "61 4801.8330078125\n",
      "62 4464.919921875\n",
      "63 4153.2373046875\n",
      "64 3864.72998046875\n",
      "65 3597.674072265625\n",
      "66 3350.31396484375\n",
      "67 3120.936279296875\n",
      "68 2908.280517578125\n",
      "69 2710.93017578125\n",
      "70 2527.8076171875\n",
      "71 2357.883544921875\n",
      "72 2199.88671875\n",
      "73 2052.991455078125\n",
      "74 1916.4521484375\n",
      "75 1789.462158203125\n",
      "76 1671.329345703125\n",
      "77 1561.3795166015625\n",
      "78 1458.96875\n",
      "79 1363.38916015625\n",
      "80 1274.34423828125\n",
      "81 1191.36376953125\n",
      "82 1114.0625\n",
      "83 1041.9693603515625\n",
      "84 974.73486328125\n",
      "85 911.9751586914062\n",
      "86 853.4268188476562\n",
      "87 798.7958374023438\n",
      "88 747.803955078125\n",
      "89 700.1676635742188\n",
      "90 655.6759033203125\n",
      "91 614.1044311523438\n",
      "92 575.2579956054688\n",
      "93 538.964599609375\n",
      "94 505.0425109863281\n",
      "95 473.3070373535156\n",
      "96 443.6288757324219\n",
      "97 415.87738037109375\n",
      "98 389.9151306152344\n",
      "99 365.6199951171875\n",
      "100 342.889892578125\n",
      "101 321.60400390625\n",
      "102 301.67559814453125\n",
      "103 283.0169982910156\n",
      "104 265.56524658203125\n",
      "105 249.222900390625\n",
      "106 233.9173583984375\n",
      "107 219.5698699951172\n",
      "108 206.12071228027344\n",
      "109 193.51943969726562\n",
      "110 181.70672607421875\n",
      "111 170.63876342773438\n",
      "112 160.2585906982422\n",
      "113 150.525146484375\n",
      "114 141.39288330078125\n",
      "115 132.8306884765625\n",
      "116 124.79652404785156\n",
      "117 117.2586669921875\n",
      "118 110.186767578125\n",
      "119 103.55529022216797\n",
      "120 97.3265151977539\n",
      "121 91.47759246826172\n",
      "122 85.99120330810547\n",
      "123 80.83800506591797\n",
      "124 76.00108337402344\n",
      "125 71.45867156982422\n",
      "126 67.19422149658203\n",
      "127 63.18925476074219\n",
      "128 59.42648696899414\n",
      "129 55.89046859741211\n",
      "130 52.56890106201172\n",
      "131 49.44901657104492\n",
      "132 46.517433166503906\n",
      "133 43.76305389404297\n",
      "134 41.17401885986328\n",
      "135 38.742279052734375\n",
      "136 36.454463958740234\n",
      "137 34.30450439453125\n",
      "138 32.282508850097656\n",
      "139 30.383010864257812\n",
      "140 28.596981048583984\n",
      "141 26.916833877563477\n",
      "142 25.337810516357422\n",
      "143 23.851154327392578\n",
      "144 22.45425796508789\n",
      "145 21.139963150024414\n",
      "146 19.9034423828125\n",
      "147 18.741106033325195\n",
      "148 17.646642684936523\n",
      "149 16.61819839477539\n",
      "150 15.64931583404541\n",
      "151 14.738133430480957\n",
      "152 13.8807373046875\n",
      "153 13.073647499084473\n",
      "154 12.314516067504883\n",
      "155 11.599804878234863\n",
      "156 10.926908493041992\n",
      "157 10.293597221374512\n",
      "158 9.697071075439453\n",
      "159 9.136494636535645\n",
      "160 8.607842445373535\n",
      "161 8.110755920410156\n",
      "162 7.642505168914795\n",
      "163 7.2015252113342285\n",
      "164 6.786452293395996\n",
      "165 6.394842147827148\n",
      "166 6.027170181274414\n",
      "167 5.680264472961426\n",
      "168 5.353686332702637\n",
      "169 5.04610013961792\n",
      "170 4.756346702575684\n",
      "171 4.483003616333008\n",
      "172 4.225959300994873\n",
      "173 3.9836597442626953\n",
      "174 3.7554640769958496\n",
      "175 3.5400662422180176\n",
      "176 3.3376286029815674\n",
      "177 3.1469483375549316\n",
      "178 2.9671883583068848\n",
      "179 2.7975919246673584\n",
      "180 2.6379573345184326\n",
      "181 2.4873716831207275\n",
      "182 2.345644474029541\n",
      "183 2.211850643157959\n",
      "184 2.0858538150787354\n",
      "185 1.967097520828247\n",
      "186 1.8551346063613892\n",
      "187 1.749650239944458\n",
      "188 1.6501781940460205\n",
      "189 1.5563948154449463\n",
      "190 1.468150019645691\n",
      "191 1.3846944570541382\n",
      "192 1.306067705154419\n",
      "193 1.2320945262908936\n",
      "194 1.162226676940918\n",
      "195 1.096409797668457\n",
      "196 1.034274935722351\n",
      "197 0.9758194088935852\n",
      "198 0.9205386638641357\n",
      "199 0.8684682250022888\n",
      "200 0.8193854689598083\n",
      "201 0.7730931043624878\n",
      "202 0.7294265627861023\n",
      "203 0.6882777214050293\n",
      "204 0.6494016647338867\n",
      "205 0.6127719283103943\n",
      "206 0.5782351493835449\n",
      "207 0.5455905199050903\n",
      "208 0.5149229764938354\n",
      "209 0.48592856526374817\n",
      "210 0.45858705043792725\n",
      "211 0.4327455461025238\n",
      "212 0.40837424993515015\n",
      "213 0.38534656167030334\n",
      "214 0.36377549171447754\n",
      "215 0.343292772769928\n",
      "216 0.32400041818618774\n",
      "217 0.30586597323417664\n",
      "218 0.28867673873901367\n",
      "219 0.2724633812904358\n",
      "220 0.2572018504142761\n",
      "221 0.24275510013103485\n",
      "222 0.22923386096954346\n",
      "223 0.2163357436656952\n",
      "224 0.20417770743370056\n",
      "225 0.19272810220718384\n",
      "226 0.18195265531539917\n",
      "227 0.17176124453544617\n",
      "228 0.1621743142604828\n",
      "229 0.15306463837623596\n",
      "230 0.14451825618743896\n",
      "231 0.13644109666347504\n",
      "232 0.12883584201335907\n",
      "233 0.12167473137378693\n",
      "234 0.11487939953804016\n",
      "235 0.10844650119543076\n",
      "236 0.10240474343299866\n",
      "237 0.096714548766613\n",
      "238 0.09127819538116455\n",
      "239 0.08617637306451797\n",
      "240 0.08139227330684662\n",
      "241 0.07685767114162445\n",
      "242 0.07256583869457245\n",
      "243 0.06853023916482925\n",
      "244 0.0646999403834343\n",
      "245 0.06110561266541481\n",
      "246 0.057695478200912476\n",
      "247 0.054519060999155045\n",
      "248 0.05151306465268135\n",
      "249 0.048665035516023636\n",
      "250 0.04593699797987938\n",
      "251 0.043388888239860535\n",
      "252 0.04097308591008186\n",
      "253 0.03870765119791031\n",
      "254 0.03655226156115532\n",
      "255 0.03452471271157265\n",
      "256 0.032600633800029755\n",
      "257 0.030812732875347137\n",
      "258 0.029101382941007614\n",
      "259 0.027483541518449783\n",
      "260 0.02597407065331936\n",
      "261 0.02453148551285267\n",
      "262 0.023164866492152214\n",
      "263 0.02188856340944767\n",
      "264 0.020693793892860413\n",
      "265 0.019555220380425453\n",
      "266 0.018482442945241928\n",
      "267 0.0174623504281044\n",
      "268 0.01651124097406864\n",
      "269 0.015600993297994137\n",
      "270 0.014747471548616886\n",
      "271 0.013943095691502094\n",
      "272 0.013170449063181877\n",
      "273 0.012452500872313976\n",
      "274 0.011771608144044876\n",
      "275 0.011128053069114685\n",
      "276 0.010524904355406761\n",
      "277 0.00994972325861454\n",
      "278 0.009410928934812546\n",
      "279 0.008894076570868492\n",
      "280 0.008421876467764378\n",
      "281 0.007967776618897915\n",
      "282 0.00753626087680459\n",
      "283 0.007134049665182829\n",
      "284 0.00675079133361578\n",
      "285 0.006389148533344269\n",
      "286 0.006052541080862284\n",
      "287 0.005727479699999094\n",
      "288 0.005424079485237598\n",
      "289 0.005136422347277403\n",
      "290 0.004868977703154087\n",
      "291 0.00461907684803009\n",
      "292 0.004378023557364941\n",
      "293 0.00415185559540987\n",
      "294 0.003936829045414925\n",
      "295 0.0037300600670278072\n",
      "296 0.00353980902582407\n",
      "297 0.0033564320765435696\n",
      "298 0.0031874640844762325\n",
      "299 0.0030273981392383575\n",
      "300 0.002874146681278944\n",
      "301 0.002729215892031789\n",
      "302 0.002593723591417074\n",
      "303 0.0024702614173293114\n",
      "304 0.002347928937524557\n",
      "305 0.0022370724473148584\n",
      "306 0.0021280997898429632\n",
      "307 0.002025405876338482\n",
      "308 0.0019283422734588385\n",
      "309 0.0018384088762104511\n",
      "310 0.001750687137246132\n",
      "311 0.0016701801214367151\n",
      "312 0.0015943389153108\n",
      "313 0.0015204704832285643\n",
      "314 0.0014501647092401981\n",
      "315 0.0013833451084792614\n",
      "316 0.0013207457959651947\n",
      "317 0.0012617118190973997\n",
      "318 0.0012071110541000962\n",
      "319 0.0011554356897249818\n",
      "320 0.0011042882688343525\n",
      "321 0.0010574935004115105\n",
      "322 0.0010137198260053992\n",
      "323 0.0009714381885714829\n",
      "324 0.0009305797284469008\n",
      "325 0.0008902257541194558\n",
      "326 0.0008522099815309048\n",
      "327 0.0008196482667699456\n",
      "328 0.000786671182140708\n",
      "329 0.0007542179664596915\n",
      "330 0.0007261987775564194\n",
      "331 0.0006971129332669079\n",
      "332 0.0006696227355860174\n",
      "333 0.0006451045628637075\n",
      "334 0.0006189222913235426\n",
      "335 0.0005951464409008622\n",
      "336 0.0005736263701692224\n",
      "337 0.000553606660105288\n",
      "338 0.0005323902005329728\n",
      "339 0.000512060010805726\n",
      "340 0.0004933312302455306\n",
      "341 0.00047610150068067014\n",
      "342 0.0004587814037222415\n",
      "343 0.00044220121344551444\n",
      "344 0.0004263517039362341\n",
      "345 0.0004117642529308796\n",
      "346 0.00039816650678403676\n",
      "347 0.0003859129792544991\n",
      "348 0.0003729920135810971\n",
      "349 0.00036047695903107524\n",
      "350 0.0003481907770037651\n",
      "351 0.00033708708360791206\n",
      "352 0.00032511926838196814\n",
      "353 0.00031556462636217475\n",
      "354 0.0003059450536966324\n",
      "355 0.0002969380293507129\n",
      "356 0.0002864725247491151\n",
      "357 0.0002776018518488854\n",
      "358 0.0002685601939447224\n",
      "359 0.00026081030955538154\n",
      "360 0.0002535399980843067\n",
      "361 0.00024606272927485406\n",
      "362 0.00023797023459337652\n",
      "363 0.00023094756761565804\n",
      "364 0.00022466242080554366\n",
      "365 0.0002186949277529493\n",
      "366 0.00021196652960497886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367 0.00020567089086398482\n",
      "368 0.00020027326536364853\n",
      "369 0.00019474867440294474\n",
      "370 0.00018893271044362336\n",
      "371 0.00018315191846340895\n",
      "372 0.00017795110761653632\n",
      "373 0.00017330158152617514\n",
      "374 0.00016887446690816432\n",
      "375 0.00016444933135062456\n",
      "376 0.00016027367382775992\n",
      "377 0.00015628222899977118\n",
      "378 0.000152921027620323\n",
      "379 0.00014884283882565796\n",
      "380 0.000144464589538984\n",
      "381 0.0001412861602148041\n",
      "382 0.00013760336150880903\n",
      "383 0.00013451404811348766\n",
      "384 0.00013101528747938573\n",
      "385 0.00012788655294571072\n",
      "386 0.00012495653936639428\n",
      "387 0.00012195236922707409\n",
      "388 0.00011911858746316284\n",
      "389 0.00011645037739071995\n",
      "390 0.0001136025384766981\n",
      "391 0.00011095836816821247\n",
      "392 0.00010884502262342721\n",
      "393 0.00010686594760045409\n",
      "394 0.00010434607247589156\n",
      "395 0.00010191217734245583\n",
      "396 9.946431237040088e-05\n",
      "397 9.736104402691126e-05\n",
      "398 9.51928595895879e-05\n",
      "399 9.341337135992944e-05\n",
      "400 9.130663966061547e-05\n",
      "401 8.932248601922765e-05\n",
      "402 8.7477543274872e-05\n",
      "403 8.593798702349886e-05\n",
      "404 8.424838597420603e-05\n",
      "405 8.221574535127729e-05\n",
      "406 8.080244151642546e-05\n",
      "407 7.968873978825286e-05\n",
      "408 7.780421583447605e-05\n",
      "409 7.623707642778754e-05\n",
      "410 7.478149200323969e-05\n",
      "411 7.283671584445983e-05\n",
      "412 7.160805398598313e-05\n",
      "413 7.017183816060424e-05\n",
      "414 6.91018722136505e-05\n",
      "415 6.783624849049374e-05\n",
      "416 6.656282494077459e-05\n",
      "417 6.52154631097801e-05\n",
      "418 6.403852603398263e-05\n",
      "419 6.304065755102783e-05\n",
      "420 6.187400867929682e-05\n",
      "421 6.0572529037017375e-05\n",
      "422 5.9321166190784425e-05\n",
      "423 5.8455552789382637e-05\n",
      "424 5.731569399358705e-05\n",
      "425 5.629360384773463e-05\n",
      "426 5.54490543436259e-05\n",
      "427 5.448064621305093e-05\n",
      "428 5.3655759984394535e-05\n",
      "429 5.2795301598962396e-05\n",
      "430 5.2163672080496326e-05\n",
      "431 5.124589370097965e-05\n",
      "432 5.053192944615148e-05\n",
      "433 4.9394715460948646e-05\n",
      "434 4.871581040788442e-05\n",
      "435 4.808999437955208e-05\n",
      "436 4.735828042612411e-05\n",
      "437 4.675401942222379e-05\n",
      "438 4.591577817336656e-05\n",
      "439 4.5293149014469236e-05\n",
      "440 4.465309757506475e-05\n",
      "441 4.405708750709891e-05\n",
      "442 4.332782918936573e-05\n",
      "443 4.2539591959211975e-05\n",
      "444 4.2099614802282304e-05\n",
      "445 4.142058969591744e-05\n",
      "446 4.08251398766879e-05\n",
      "447 4.010723205283284e-05\n",
      "448 3.945496791857295e-05\n",
      "449 3.915922570740804e-05\n",
      "450 3.851622750516981e-05\n",
      "451 3.80073361156974e-05\n",
      "452 3.753839700948447e-05\n",
      "453 3.693065082188696e-05\n",
      "454 3.6363569961395115e-05\n",
      "455 3.5965407732874155e-05\n",
      "456 3.546785228536464e-05\n",
      "457 3.4692551707848907e-05\n",
      "458 3.441534499870613e-05\n",
      "459 3.405947791179642e-05\n",
      "460 3.36565644829534e-05\n",
      "461 3.336456211400218e-05\n",
      "462 3.30209695675876e-05\n",
      "463 3.262327300035395e-05\n",
      "464 3.212162118870765e-05\n",
      "465 3.169589763274416e-05\n",
      "466 3.1214098271448165e-05\n",
      "467 3.084761192440055e-05\n",
      "468 3.055075285374187e-05\n",
      "469 3.0186605727067217e-05\n",
      "470 2.9764623832306825e-05\n",
      "471 2.9380276828305796e-05\n",
      "472 2.9139038815628737e-05\n",
      "473 2.8729113182635047e-05\n",
      "474 2.8296877644606866e-05\n",
      "475 2.8002958060824312e-05\n",
      "476 2.7632322598947212e-05\n",
      "477 2.7305683033773676e-05\n",
      "478 2.7053754820371978e-05\n",
      "479 2.6657451599021442e-05\n",
      "480 2.643674633873161e-05\n",
      "481 2.614330151118338e-05\n",
      "482 2.5736133466125466e-05\n",
      "483 2.5521114366711117e-05\n",
      "484 2.524656883906573e-05\n",
      "485 2.5008752345456742e-05\n",
      "486 2.475570909155067e-05\n",
      "487 2.441891592752654e-05\n",
      "488 2.4112705432344228e-05\n",
      "489 2.3940676328493282e-05\n",
      "490 2.365076397836674e-05\n",
      "491 2.344490167160984e-05\n",
      "492 2.313868208148051e-05\n",
      "493 2.297700848430395e-05\n",
      "494 2.2625068595516495e-05\n",
      "495 2.251473233627621e-05\n",
      "496 2.2353824533638544e-05\n",
      "497 2.2034821085981093e-05\n",
      "498 2.192475221818313e-05\n",
      "499 2.1859728803974576e-05\n"
     ]
    }
   ],
   "source": [
    "N , D_IN , H , D_OUT = 64 , 1000, 100, 10 # 64个数据，输入时1000维 隐层100维 输出是10维的\n",
    "# 随机创建一些训练数据\n",
    "x = torch.randn(N,D_IN) # x = np.random.randn(N,D_IN)\n",
    "y = torch.randn(N,D_OUT) # y = np.random.randn(N,D_OUT)\n",
    "\n",
    "w1 = torch.randn(D_IN, H, requires_grad = True) # w1 = np.random.randn(D_IN,H)\n",
    "w2 = torch.randn(H, D_OUT, requires_grad = True) # w2 = np.random.randn(H,D_OUT)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "#搭建神经网络并训练\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = (y_pred - y).pow(2).sum() # 这里不适用 item（） 是因为，我们要使用 tensor 的 backward 方法，不用把loss转换为数字\n",
    "    print(it,loss.item())\n",
    "    # Backwrad pass\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    # updata weight of w1 and w2\n",
    "    # 所有的 tensor 的计算在 pytorch 里面都是一个 compute graph 计算图，有些简单的计算为了不要让计算图占内存，就进行处理\n",
    "    with torch.no_grad():\n",
    "        # 使用这种方法以后就不会再将 w1 w2 的 gradient 记下来了\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_() # 这里使用 gard。zero() 是为了清零上次计算的梯度，如果不清零，系统会默认将每次的 grad 进行累加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch:nn\n",
    "这次我们使用 pytorch 中的 nn 库来构建网络。使用 pytorch autograd 来构建计算图和计算 gradients，然后 pytorch 会帮我们自动计算 gradient。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "F:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 32353590.0\n",
      "1 30785086.0\n",
      "2 34271972.0\n",
      "3 36053032.0\n",
      "4 31488762.0\n",
      "5 21031004.0\n",
      "6 11212498.0\n",
      "7 5348658.5\n",
      "8 2717670.5\n",
      "9 1613997.25\n",
      "10 1121900.875\n",
      "11 864857.25\n",
      "12 704982.8125\n",
      "13 591283.1875\n",
      "14 503704.15625\n",
      "15 433212.84375\n",
      "16 375167.59375\n",
      "17 326726.09375\n",
      "18 285919.75\n",
      "19 251284.0\n",
      "20 221721.796875\n",
      "21 196348.34375\n",
      "22 174454.09375\n",
      "23 155473.4375\n",
      "24 138946.234375\n",
      "25 124491.2734375\n",
      "26 111822.5859375\n",
      "27 100665.5546875\n",
      "28 90821.671875\n",
      "29 82106.2265625\n",
      "30 74369.3359375\n",
      "31 67487.4140625\n",
      "32 61361.48046875\n",
      "33 55885.19921875\n",
      "34 50975.4453125\n",
      "35 46574.59765625\n",
      "36 42612.68359375\n",
      "37 39039.41796875\n",
      "38 35818.38671875\n",
      "39 32907.19140625\n",
      "40 30264.646484375\n",
      "41 27864.61328125\n",
      "42 25683.224609375\n",
      "43 23694.69140625\n",
      "44 21880.07421875\n",
      "45 20222.740234375\n",
      "46 18705.994140625\n",
      "47 17316.029296875\n",
      "48 16042.826171875\n",
      "49 14875.099609375\n",
      "50 13803.2373046875\n",
      "51 12817.318359375\n",
      "52 11909.7158203125\n",
      "53 11073.091796875\n",
      "54 10301.09765625\n",
      "55 9588.8037109375\n",
      "56 8931.341796875\n",
      "57 8322.8408203125\n",
      "58 7759.982421875\n",
      "59 7240.3662109375\n",
      "60 6758.8642578125\n",
      "61 6312.0849609375\n",
      "62 5897.39892578125\n",
      "63 5512.1982421875\n",
      "64 5154.2314453125\n",
      "65 4821.525390625\n",
      "66 4511.91748046875\n",
      "67 4223.697265625\n",
      "68 3955.45361328125\n",
      "69 3705.354736328125\n",
      "70 3472.23876953125\n",
      "71 3254.896484375\n",
      "72 3052.01806640625\n",
      "73 2862.6533203125\n",
      "74 2685.843017578125\n",
      "75 2520.66064453125\n",
      "76 2366.45361328125\n",
      "77 2222.3017578125\n",
      "78 2087.4541015625\n",
      "79 1961.316162109375\n",
      "80 1843.223388671875\n",
      "81 1732.6903076171875\n",
      "82 1629.1739501953125\n",
      "83 1532.1417236328125\n",
      "84 1441.221435546875\n",
      "85 1355.9749755859375\n",
      "86 1276.0369873046875\n",
      "87 1201.1024169921875\n",
      "88 1130.7542724609375\n",
      "89 1064.799072265625\n",
      "90 1002.9890747070312\n",
      "91 944.9376831054688\n",
      "92 890.4005126953125\n",
      "93 839.1572265625\n",
      "94 791.0075073242188\n",
      "95 745.7506103515625\n",
      "96 703.198974609375\n",
      "97 663.194091796875\n",
      "98 625.5465087890625\n",
      "99 590.1372680664062\n",
      "100 556.8045654296875\n",
      "101 525.43408203125\n",
      "102 495.90472412109375\n",
      "103 468.1054382324219\n",
      "104 441.92279052734375\n",
      "105 417.2665710449219\n",
      "106 394.0348205566406\n",
      "107 372.14141845703125\n",
      "108 351.51629638671875\n",
      "109 332.0756530761719\n",
      "110 313.7472229003906\n",
      "111 296.4693298339844\n",
      "112 280.17535400390625\n",
      "113 264.8013916015625\n",
      "114 250.31356811523438\n",
      "115 236.63784790039062\n",
      "116 223.73538208007812\n",
      "117 211.55511474609375\n",
      "118 200.0631103515625\n",
      "119 189.2159423828125\n",
      "120 178.97634887695312\n",
      "121 169.30503845214844\n",
      "122 160.17483520507812\n",
      "123 151.54757690429688\n",
      "124 143.40245056152344\n",
      "125 135.70675659179688\n",
      "126 128.43743896484375\n",
      "127 121.56864929199219\n",
      "128 115.0794906616211\n",
      "129 108.94393920898438\n",
      "130 103.14354705810547\n",
      "131 97.66513061523438\n",
      "132 92.48454284667969\n",
      "133 87.5853500366211\n",
      "134 82.95382690429688\n",
      "135 78.5723648071289\n",
      "136 74.42845916748047\n",
      "137 70.50840759277344\n",
      "138 66.8013916015625\n",
      "139 63.29308319091797\n",
      "140 59.97356414794922\n",
      "141 56.83329391479492\n",
      "142 53.86261749267578\n",
      "143 51.05282974243164\n",
      "144 48.394126892089844\n",
      "145 45.87655258178711\n",
      "146 43.49401092529297\n",
      "147 41.237857818603516\n",
      "148 39.10212707519531\n",
      "149 37.078243255615234\n",
      "150 35.16238784790039\n",
      "151 33.34810256958008\n",
      "152 31.62932014465332\n",
      "153 30.000593185424805\n",
      "154 28.45772361755371\n",
      "155 26.9955997467041\n",
      "156 25.609943389892578\n",
      "157 24.298913955688477\n",
      "158 23.053972244262695\n",
      "159 21.875301361083984\n",
      "160 20.757848739624023\n",
      "161 19.698232650756836\n",
      "162 18.695234298706055\n",
      "163 17.74357795715332\n",
      "164 16.841089248657227\n",
      "165 15.985156059265137\n",
      "166 15.173839569091797\n",
      "167 14.404974937438965\n",
      "168 13.675599098205566\n",
      "169 12.98325252532959\n",
      "170 12.327191352844238\n",
      "171 11.70479965209961\n",
      "172 11.11451244354248\n",
      "173 10.554174423217773\n",
      "174 10.023100852966309\n",
      "175 9.518573760986328\n",
      "176 9.040637969970703\n",
      "177 8.586299896240234\n",
      "178 8.156203269958496\n",
      "179 7.747066020965576\n",
      "180 7.359420299530029\n",
      "181 6.990941047668457\n",
      "182 6.641249656677246\n",
      "183 6.309746742248535\n",
      "184 5.9953107833862305\n",
      "185 5.696314334869385\n",
      "186 5.412624835968018\n",
      "187 5.143149375915527\n",
      "188 4.887669563293457\n",
      "189 4.64473819732666\n",
      "190 4.414438724517822\n",
      "191 4.195316314697266\n",
      "192 3.9873807430267334\n",
      "193 3.7898335456848145\n",
      "194 3.602431297302246\n",
      "195 3.4244799613952637\n",
      "196 3.2552218437194824\n",
      "197 3.094463348388672\n",
      "198 2.9418070316314697\n",
      "199 2.7969374656677246\n",
      "200 2.6592350006103516\n",
      "201 2.5284368991851807\n",
      "202 2.4040746688842773\n",
      "203 2.2858598232269287\n",
      "204 2.1737399101257324\n",
      "205 2.067018508911133\n",
      "206 1.9656575918197632\n",
      "207 1.8695062398910522\n",
      "208 1.7779449224472046\n",
      "209 1.690796971321106\n",
      "210 1.6083694696426392\n",
      "211 1.529938817024231\n",
      "212 1.4553431272506714\n",
      "213 1.3842477798461914\n",
      "214 1.3168118000030518\n",
      "215 1.2526339292526245\n",
      "216 1.1916499137878418\n",
      "217 1.13369619846344\n",
      "218 1.0785001516342163\n",
      "219 1.0261846780776978\n",
      "220 0.976372241973877\n",
      "221 0.9291061162948608\n",
      "222 0.8840111494064331\n",
      "223 0.8411186933517456\n",
      "224 0.8004892468452454\n",
      "225 0.7617112398147583\n",
      "226 0.7249361872673035\n",
      "227 0.6899040341377258\n",
      "228 0.656576931476593\n",
      "229 0.6249122023582458\n",
      "230 0.5947568416595459\n",
      "231 0.5661202669143677\n",
      "232 0.5388380885124207\n",
      "233 0.5129170417785645\n",
      "234 0.48825377225875854\n",
      "235 0.4648379683494568\n",
      "236 0.4424450099468231\n",
      "237 0.4212426543235779\n",
      "238 0.4010537266731262\n",
      "239 0.3817704916000366\n",
      "240 0.3634934425354004\n",
      "241 0.346073716878891\n",
      "242 0.3295039236545563\n",
      "243 0.31373727321624756\n",
      "244 0.2987489700317383\n",
      "245 0.28447669744491577\n",
      "246 0.27087166905403137\n",
      "247 0.2579317092895508\n",
      "248 0.2456056922674179\n",
      "249 0.23391370475292206\n",
      "250 0.22278425097465515\n",
      "251 0.21215377748012543\n",
      "252 0.20209607481956482\n",
      "253 0.19248008728027344\n",
      "254 0.18330402672290802\n",
      "255 0.1746072769165039\n",
      "256 0.16632749140262604\n",
      "257 0.15843415260314941\n",
      "258 0.15091738104820251\n",
      "259 0.14379964768886566\n",
      "260 0.1369725614786148\n",
      "261 0.13049322366714478\n",
      "262 0.12430520355701447\n",
      "263 0.11841963976621628\n",
      "264 0.11283364146947861\n",
      "265 0.10750500857830048\n",
      "266 0.10242410004138947\n",
      "267 0.09761174768209457\n",
      "268 0.09303954988718033\n",
      "269 0.08865281939506531\n",
      "270 0.08447686582803726\n",
      "271 0.08048133552074432\n",
      "272 0.07667742669582367\n",
      "273 0.07309692353010178\n",
      "274 0.06963621079921722\n",
      "275 0.06637580692768097\n",
      "276 0.06327559053897858\n",
      "277 0.0603039413690567\n",
      "278 0.057476457208395004\n",
      "279 0.054792728275060654\n",
      "280 0.052216872572898865\n",
      "281 0.049773458391427994\n",
      "282 0.04744480177760124\n",
      "283 0.045230474323034286\n",
      "284 0.043123017996549606\n",
      "285 0.04109926521778107\n",
      "286 0.03918111324310303\n",
      "287 0.03736457973718643\n",
      "288 0.03562277555465698\n",
      "289 0.03396886959671974\n",
      "290 0.032392315566539764\n",
      "291 0.030883600935339928\n",
      "292 0.029449468478560448\n",
      "293 0.028090232983231544\n",
      "294 0.026796087622642517\n",
      "295 0.025545233860611916\n",
      "296 0.02436618134379387\n",
      "297 0.02324485592544079\n",
      "298 0.022171922028064728\n",
      "299 0.02114064246416092\n",
      "300 0.02018071338534355\n",
      "301 0.019250327721238136\n",
      "302 0.018364163115620613\n",
      "303 0.017528261989355087\n",
      "304 0.016719570383429527\n",
      "305 0.01595882698893547\n",
      "306 0.015224870294332504\n",
      "307 0.014527348801493645\n",
      "308 0.013865021988749504\n",
      "309 0.013235686346888542\n",
      "310 0.012630530633032322\n",
      "311 0.012064283713698387\n",
      "312 0.011518402956426144\n",
      "313 0.010994800366461277\n",
      "314 0.010499835014343262\n",
      "315 0.010027534328401089\n",
      "316 0.00957518070936203\n",
      "317 0.009144690819084644\n",
      "318 0.008739691227674484\n",
      "319 0.008350320160388947\n",
      "320 0.007978340610861778\n",
      "321 0.007622776087373495\n",
      "322 0.007290821522474289\n",
      "323 0.006972378119826317\n",
      "324 0.0066591608338057995\n",
      "325 0.0063674114644527435\n",
      "326 0.006090066861361265\n",
      "327 0.0058161127381026745\n",
      "328 0.005561031401157379\n",
      "329 0.005322574637830257\n",
      "330 0.005089838523417711\n",
      "331 0.004872018471360207\n",
      "332 0.004661026410758495\n",
      "333 0.0044590188190341\n",
      "334 0.00427086278796196\n",
      "335 0.0040892367251217365\n",
      "336 0.0039192126132547855\n",
      "337 0.0037493379786610603\n",
      "338 0.0035956627689301968\n",
      "339 0.0034429619554430246\n",
      "340 0.003302007680758834\n",
      "341 0.0031621954403817654\n",
      "342 0.0030320098157972097\n",
      "343 0.0029090847820043564\n",
      "344 0.002793126506730914\n",
      "345 0.0026786585804075003\n",
      "346 0.002569250063970685\n",
      "347 0.0024661303032189608\n",
      "348 0.0023697963915765285\n",
      "349 0.0022744920570403337\n",
      "350 0.0021840662229806185\n",
      "351 0.002096230164170265\n",
      "352 0.002015453763306141\n",
      "353 0.0019368238281458616\n",
      "354 0.0018625677330419421\n",
      "355 0.0017893050098791718\n",
      "356 0.0017197178676724434\n",
      "357 0.0016544716199859977\n",
      "358 0.0015907275956124067\n",
      "359 0.0015307861613109708\n",
      "360 0.0014747126260772347\n",
      "361 0.0014211881207302213\n",
      "362 0.0013683178694918752\n",
      "363 0.0013203163398429751\n",
      "364 0.0012711436720564961\n",
      "365 0.0012257836060598493\n",
      "366 0.0011835905024781823\n",
      "367 0.0011409324361011386\n",
      "368 0.0011009641457349062\n",
      "369 0.0010632931953296065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370 0.0010253206128254533\n",
      "371 0.0009889404755085707\n",
      "372 0.0009556067525409162\n",
      "373 0.0009259427315555513\n",
      "374 0.0008944894652813673\n",
      "375 0.0008652627002447844\n",
      "376 0.0008358624763786793\n",
      "377 0.000809226359706372\n",
      "378 0.0007838204619474709\n",
      "379 0.0007578371441923082\n",
      "380 0.0007334807305596769\n",
      "381 0.0007113913306966424\n",
      "382 0.0006890497170388699\n",
      "383 0.0006664707907475531\n",
      "384 0.0006468904321081936\n",
      "385 0.0006258089561015368\n",
      "386 0.0006055851117707789\n",
      "387 0.000588055292610079\n",
      "388 0.0005701393238268793\n",
      "389 0.0005525779561139643\n",
      "390 0.0005362280644476414\n",
      "391 0.0005190488300286233\n",
      "392 0.0005058722454123199\n",
      "393 0.000489954836666584\n",
      "394 0.0004758589493576437\n",
      "395 0.0004634462238755077\n",
      "396 0.00044955970952287316\n",
      "397 0.0004373863630462438\n",
      "398 0.0004255702078808099\n",
      "399 0.0004139919183216989\n",
      "400 0.0004025536763947457\n",
      "401 0.00039043862489052117\n",
      "402 0.00038062490057200193\n",
      "403 0.00037055820575915277\n",
      "404 0.00036080676363781095\n",
      "405 0.00035117409424856305\n",
      "406 0.0003415191313251853\n",
      "407 0.0003330720937810838\n",
      "408 0.0003244238323532045\n",
      "409 0.0003160497872158885\n",
      "410 0.0003081314789596945\n",
      "411 0.00029977934900671244\n",
      "412 0.00029341509798541665\n",
      "413 0.00028543933876790106\n",
      "414 0.00027869254699908197\n",
      "415 0.0002712758432608098\n",
      "416 0.0002647461951710284\n",
      "417 0.0002581152075435966\n",
      "418 0.00025219813687726855\n",
      "419 0.0002463496057316661\n",
      "420 0.00024098955327644944\n",
      "421 0.00023488840088248253\n",
      "422 0.00022951366554480046\n",
      "423 0.00022419785091187805\n",
      "424 0.0002194371190853417\n",
      "425 0.00021396168449427933\n",
      "426 0.00020931621838826686\n",
      "427 0.00020393193699419498\n",
      "428 0.00019900671031791717\n",
      "429 0.00019531291036400944\n",
      "430 0.00019088062981609255\n",
      "431 0.00018684309907257557\n",
      "432 0.00018226171960122883\n",
      "433 0.00017855563783086836\n",
      "434 0.0001745233021210879\n",
      "435 0.0001712073280941695\n",
      "436 0.00016741051513236016\n",
      "437 0.00016386732750106603\n",
      "438 0.0001608506718184799\n",
      "439 0.000157629037857987\n",
      "440 0.00015471770893782377\n",
      "441 0.00015163749048952013\n",
      "442 0.00014832188026048243\n",
      "443 0.0001457269099773839\n",
      "444 0.00014238191943150014\n",
      "445 0.00013990022125653923\n",
      "446 0.00013697869144380093\n",
      "447 0.00013409701932687312\n",
      "448 0.0001314047840423882\n",
      "449 0.00012909471115563065\n",
      "450 0.00012666868860833347\n",
      "451 0.00012377196981105953\n",
      "452 0.00012151995906606317\n",
      "453 0.0001200917613459751\n",
      "454 0.0001175308643723838\n",
      "455 0.00011531468771863729\n",
      "456 0.00011322517093503848\n",
      "457 0.0001110361990868114\n",
      "458 0.00010892889986280352\n",
      "459 0.00010710886999731883\n",
      "460 0.00010528891289141029\n",
      "461 0.00010317638225387782\n",
      "462 0.00010127111454494298\n",
      "463 9.975023567676544e-05\n",
      "464 9.742222755448893e-05\n",
      "465 9.625015809433535e-05\n",
      "466 9.424042218597606e-05\n",
      "467 9.26678185351193e-05\n",
      "468 9.085334750125185e-05\n",
      "469 8.955827070167288e-05\n",
      "470 8.789105777395889e-05\n",
      "471 8.626664930488914e-05\n",
      "472 8.492475171806291e-05\n",
      "473 8.362797962035984e-05\n",
      "474 8.24430026113987e-05\n",
      "475 8.113567309919745e-05\n",
      "476 8.016134961508214e-05\n",
      "477 7.8729928645771e-05\n",
      "478 7.734477549092844e-05\n",
      "479 7.572642061859369e-05\n",
      "480 7.454243313986808e-05\n",
      "481 7.364561315625906e-05\n",
      "482 7.242183346534148e-05\n",
      "483 7.10533422534354e-05\n",
      "484 6.993662827881053e-05\n",
      "485 6.859907443867996e-05\n",
      "486 6.75699848216027e-05\n",
      "487 6.647084228461608e-05\n",
      "488 6.549347745021805e-05\n",
      "489 6.466032209573314e-05\n",
      "490 6.371053314069286e-05\n",
      "491 6.286030111368746e-05\n",
      "492 6.187393591972068e-05\n",
      "493 6.124357605585828e-05\n",
      "494 6.0307138483040035e-05\n",
      "495 5.928703467361629e-05\n",
      "496 5.856884308741428e-05\n",
      "497 5.781367144663818e-05\n",
      "498 5.697041342500597e-05\n",
      "499 5.6099132052622736e-05\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "N , D_IN , H , D_OUT = 64 , 1000, 100, 10 # 64个数据，输入时1000维 隐层100维 输出是10维的\n",
    "# 随机创建一些训练数据\n",
    "x = torch.randn(N,D_IN) # x = np.random.randn(N,D_IN)\n",
    "y = torch.randn(N,D_OUT) # y = np.random.randn(N,D_OUT)\n",
    "\n",
    "w1 = torch.randn(D_IN, H, requires_grad = True) # w1 = np.random.randn(D_IN,H)\n",
    "w2 = torch.randn(H, D_OUT, requires_grad = True) # w2 = np.random.randn(H,D_OUT)\n",
    "learning_rate = 1e-6\n",
    "\n",
    "#搭建神经网络并训练\n",
    "# 使用 nn 来搭建一个神经网络\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_IN,H), # 默认是 y = w* x + b ,这里的 b 可以通过设置进行取消 bias = False\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H,D_OUT)\n",
    ")\n",
    "# 对模型进行初始化，可以提升训练效果\n",
    "torch.nn.init.normal(model[0].weight) # model[0] 指的是第0层 \n",
    "torch.nn.init.normal(model[2].weight) # model[2] 指的是第2层 \n",
    "\n",
    "\n",
    "# 使用 GPU 来计算\n",
    "# model = model.to_('cuda:0')\n",
    "# model = model.cuda()\n",
    "loss_fn = nn.MSELoss(reduction = 'sum') #这里只是 loss function \n",
    "\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = model(x) # model 会直接 进行 forward pass  即model.forward()\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = loss_fn(y_pred , y) # 这里是一个 compute graph\n",
    "    \n",
    "    print(it,loss.item())\n",
    "    \n",
    "    # Backwrad pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # updata weight of w1 and w2\n",
    "    # 所有的 tensor 的计算在 pytorch 里面都是一个 compute graph 计算图，有些简单的计算为了不要让计算图占内存，就进行处理\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters(): # 每个 param 包含两个参数（tensor，grad）\n",
    "            param -= learning_rate * param.grad\n",
    "    model.zero_grad()# 在计算下一次梯度之前先清零之前计算的梯度值，不然梯度值会进行累加       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1000, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch ： optim\n",
    "使用 optim 可以让我们不再手动更新模型的weights，而是使用 optim 这个包来帮助我们进行更新参数，optim 刻个package 提供了各种不同的模型的优化方法，包括 SGD + momentum ，RMSProp ， Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "F:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 29691460.0\n",
      "1 23905236.0\n",
      "2 21827168.0\n",
      "3 19923534.0\n",
      "4 16831732.0\n",
      "5 12794285.0\n",
      "6 8798722.0\n",
      "7 5673844.5\n",
      "8 3581222.25\n",
      "9 2305052.75\n",
      "10 1553070.75\n",
      "11 1107902.5\n",
      "12 834538.5\n",
      "13 657531.5625\n",
      "14 535732.375\n",
      "15 447027.5\n",
      "16 379338.53125\n",
      "17 325708.71875\n",
      "18 282067.0\n",
      "19 245834.9375\n",
      "20 215434.640625\n",
      "21 189602.859375\n",
      "22 167506.09375\n",
      "23 148467.96875\n",
      "24 131996.21875\n",
      "25 117671.6640625\n",
      "26 105164.40625\n",
      "27 94210.3671875\n",
      "28 84593.8828125\n",
      "29 76112.890625\n",
      "30 68617.796875\n",
      "31 61974.09765625\n",
      "32 56068.21875\n",
      "33 50820.0546875\n",
      "34 46135.43359375\n",
      "35 41944.5390625\n",
      "36 38188.8203125\n",
      "37 34820.7578125\n",
      "38 31793.10546875\n",
      "39 29066.21875\n",
      "40 26605.142578125\n",
      "41 24380.08203125\n",
      "42 22366.669921875\n",
      "43 20543.1953125\n",
      "44 18890.076171875\n",
      "45 17388.046875\n",
      "46 16021.337890625\n",
      "47 14775.4677734375\n",
      "48 13638.421875\n",
      "49 12600.4345703125\n",
      "50 11651.359375\n",
      "51 10782.16015625\n",
      "52 9985.728515625\n",
      "53 9255.9091796875\n",
      "54 8586.06640625\n",
      "55 7970.2275390625\n",
      "56 7403.94140625\n",
      "57 6882.5673828125\n",
      "58 6401.9521484375\n",
      "59 5958.94970703125\n",
      "60 5549.83203125\n",
      "61 5171.822265625\n",
      "62 4822.39208984375\n",
      "63 4499.27490234375\n",
      "64 4199.97509765625\n",
      "65 3922.61083984375\n",
      "66 3665.38916015625\n",
      "67 3426.7412109375\n",
      "68 3205.203369140625\n",
      "69 2999.595703125\n",
      "70 2808.322265625\n",
      "71 2630.38818359375\n",
      "72 2464.83154296875\n",
      "73 2310.641845703125\n",
      "74 2166.984130859375\n",
      "75 2033.1837158203125\n",
      "76 1908.23291015625\n",
      "77 1791.6629638671875\n",
      "78 1682.7808837890625\n",
      "79 1581.0948486328125\n",
      "80 1486.099609375\n",
      "81 1397.22314453125\n",
      "82 1314.0780029296875\n",
      "83 1236.260498046875\n",
      "84 1163.4193115234375\n",
      "85 1095.1363525390625\n",
      "86 1031.166015625\n",
      "87 971.1467895507812\n",
      "88 914.8741455078125\n",
      "89 862.1083984375\n",
      "90 812.59033203125\n",
      "91 766.1039428710938\n",
      "92 722.4330444335938\n",
      "93 681.4149780273438\n",
      "94 642.8800048828125\n",
      "95 606.6588134765625\n",
      "96 572.5863647460938\n",
      "97 540.5327758789062\n",
      "98 510.37530517578125\n",
      "99 481.99212646484375\n",
      "100 455.29022216796875\n",
      "101 430.14068603515625\n",
      "102 406.456787109375\n",
      "103 384.1316833496094\n",
      "104 363.0907287597656\n",
      "105 343.2712097167969\n",
      "106 324.5727844238281\n",
      "107 306.9427490234375\n",
      "108 290.3147277832031\n",
      "109 274.6299133300781\n",
      "110 259.8364562988281\n",
      "111 245.86300659179688\n",
      "112 232.6746063232422\n",
      "113 220.22000122070312\n",
      "114 208.4610137939453\n",
      "115 197.3559112548828\n",
      "116 186.86065673828125\n",
      "117 176.94598388671875\n",
      "118 167.57716369628906\n",
      "119 158.72093200683594\n",
      "120 150.3505401611328\n",
      "121 142.43263244628906\n",
      "122 134.9466552734375\n",
      "123 127.8671875\n",
      "124 121.1703109741211\n",
      "125 114.8375473022461\n",
      "126 108.84733581542969\n",
      "127 103.17383575439453\n",
      "128 97.80518341064453\n",
      "129 92.7234878540039\n",
      "130 87.91337585449219\n",
      "131 83.36064910888672\n",
      "132 79.04895782470703\n",
      "133 74.96778869628906\n",
      "134 71.10115051269531\n",
      "135 67.43977355957031\n",
      "136 63.97125244140625\n",
      "137 60.68437194824219\n",
      "138 57.569419860839844\n",
      "139 54.61769485473633\n",
      "140 51.821048736572266\n",
      "141 49.1728401184082\n",
      "142 46.6612434387207\n",
      "143 44.280860900878906\n",
      "144 42.02462387084961\n",
      "145 39.884788513183594\n",
      "146 37.85604476928711\n",
      "147 35.932037353515625\n",
      "148 34.108299255371094\n",
      "149 32.379905700683594\n",
      "150 30.738920211791992\n",
      "151 29.181957244873047\n",
      "152 27.706859588623047\n",
      "153 26.306652069091797\n",
      "154 24.978647232055664\n",
      "155 23.719255447387695\n",
      "156 22.52334976196289\n",
      "157 21.388671875\n",
      "158 20.312339782714844\n",
      "159 19.2906551361084\n",
      "160 18.32113265991211\n",
      "161 17.400894165039062\n",
      "162 16.527814865112305\n",
      "163 15.699728965759277\n",
      "164 14.913317680358887\n",
      "165 14.166889190673828\n",
      "166 13.457566261291504\n",
      "167 12.784272193908691\n",
      "168 12.145209312438965\n",
      "169 11.538226127624512\n",
      "170 10.962437629699707\n",
      "171 10.415963172912598\n",
      "172 9.896387100219727\n",
      "173 9.40286922454834\n",
      "174 8.93480396270752\n",
      "175 8.490128517150879\n",
      "176 8.06795597076416\n",
      "177 7.666861534118652\n",
      "178 7.285479545593262\n",
      "179 6.9236741065979\n",
      "180 6.580052852630615\n",
      "181 6.253729343414307\n",
      "182 5.943571090698242\n",
      "183 5.6485276222229\n",
      "184 5.368587017059326\n",
      "185 5.102779865264893\n",
      "186 4.850159168243408\n",
      "187 4.6100640296936035\n",
      "188 4.381953716278076\n",
      "189 4.165307998657227\n",
      "190 3.9594969749450684\n",
      "191 3.763925552368164\n",
      "192 3.578019618988037\n",
      "193 3.4011473655700684\n",
      "194 3.2333011627197266\n",
      "195 3.0740065574645996\n",
      "196 2.922243356704712\n",
      "197 2.7780580520629883\n",
      "198 2.6414501667022705\n",
      "199 2.5111498832702637\n",
      "200 2.387376308441162\n",
      "201 2.269883394241333\n",
      "202 2.1582984924316406\n",
      "203 2.0519604682922363\n",
      "204 1.9511483907699585\n",
      "205 1.8553749322891235\n",
      "206 1.7640206813812256\n",
      "207 1.6772878170013428\n",
      "208 1.5948997735977173\n",
      "209 1.5165859460830688\n",
      "210 1.4421228170394897\n",
      "211 1.3713213205337524\n",
      "212 1.3041048049926758\n",
      "213 1.2401154041290283\n",
      "214 1.1792916059494019\n",
      "215 1.1213812828063965\n",
      "216 1.0664395093917847\n",
      "217 1.0142402648925781\n",
      "218 0.9645628929138184\n",
      "219 0.9173345565795898\n",
      "220 0.8723788261413574\n",
      "221 0.8296613693237305\n",
      "222 0.789080798625946\n",
      "223 0.750512421131134\n",
      "224 0.7137512564659119\n",
      "225 0.6787715554237366\n",
      "226 0.6456124782562256\n",
      "227 0.6140680909156799\n",
      "228 0.5841094851493835\n",
      "229 0.5555685758590698\n",
      "230 0.5283639430999756\n",
      "231 0.5026243925094604\n",
      "232 0.47804415225982666\n",
      "233 0.45465603470802307\n",
      "234 0.432538777589798\n",
      "235 0.4114287197589874\n",
      "236 0.39135852456092834\n",
      "237 0.3722798824310303\n",
      "238 0.35401690006256104\n",
      "239 0.3367290496826172\n",
      "240 0.32034972310066223\n",
      "241 0.30471134185791016\n",
      "242 0.2898693084716797\n",
      "243 0.27575308084487915\n",
      "244 0.2623656690120697\n",
      "245 0.24953652918338776\n",
      "246 0.23742042481899261\n",
      "247 0.22587503492832184\n",
      "248 0.21480733156204224\n",
      "249 0.20438185334205627\n",
      "250 0.1944001317024231\n",
      "251 0.18498176336288452\n",
      "252 0.1759754866361618\n",
      "253 0.16741852462291718\n",
      "254 0.15926317870616913\n",
      "255 0.1515527367591858\n",
      "256 0.14416535198688507\n",
      "257 0.13708940148353577\n",
      "258 0.13048134744167328\n",
      "259 0.12413135170936584\n",
      "260 0.11809153854846954\n",
      "261 0.11234018951654434\n",
      "262 0.10689766705036163\n",
      "263 0.1017163023352623\n",
      "264 0.09676077216863632\n",
      "265 0.09209910035133362\n",
      "266 0.08764813840389252\n",
      "267 0.08335885405540466\n",
      "268 0.07930045574903488\n",
      "269 0.07544927299022675\n",
      "270 0.07178088277578354\n",
      "271 0.06832952052354813\n",
      "272 0.06500713527202606\n",
      "273 0.0618748664855957\n",
      "274 0.05886484310030937\n",
      "275 0.056001052260398865\n",
      "276 0.05327745899558067\n",
      "277 0.050704870373010635\n",
      "278 0.048255980014801025\n",
      "279 0.045915018767118454\n",
      "280 0.04370354488492012\n",
      "281 0.041590627282857895\n",
      "282 0.039584849029779434\n",
      "283 0.037665896117687225\n",
      "284 0.03584424406290054\n",
      "285 0.03408670052886009\n",
      "286 0.03246699646115303\n",
      "287 0.030900629237294197\n",
      "288 0.02937956713140011\n",
      "289 0.027976110577583313\n",
      "290 0.02661363035440445\n",
      "291 0.02533249370753765\n",
      "292 0.024125320836901665\n",
      "293 0.02298513986170292\n",
      "294 0.021866893395781517\n",
      "295 0.020809827372431755\n",
      "296 0.019816551357507706\n",
      "297 0.018855135887861252\n",
      "298 0.017967581748962402\n",
      "299 0.017107650637626648\n",
      "300 0.016292521730065346\n",
      "301 0.015506261959671974\n",
      "302 0.014771908521652222\n",
      "303 0.01406908966600895\n",
      "304 0.013400202617049217\n",
      "305 0.01276329718530178\n",
      "306 0.012157504446804523\n",
      "307 0.011573189869523048\n",
      "308 0.011023465543985367\n",
      "309 0.010503818280994892\n",
      "310 0.010010645724833012\n",
      "311 0.009542963467538357\n",
      "312 0.00909703504294157\n",
      "313 0.008667233400046825\n",
      "314 0.008271005935966969\n",
      "315 0.007877237163484097\n",
      "316 0.0075150178745388985\n",
      "317 0.007156310603022575\n",
      "318 0.0068268803879618645\n",
      "319 0.006514855194836855\n",
      "320 0.006207640282809734\n",
      "321 0.005925158504396677\n",
      "322 0.005649109371006489\n",
      "323 0.005392561201006174\n",
      "324 0.005142634268850088\n",
      "325 0.004904314409941435\n",
      "326 0.004684665240347385\n",
      "327 0.004474661312997341\n",
      "328 0.004267992451786995\n",
      "329 0.0040801106952130795\n",
      "330 0.003894037799909711\n",
      "331 0.0037187954876571894\n",
      "332 0.00355531251989305\n",
      "333 0.0033980209846049547\n",
      "334 0.0032478063367307186\n",
      "335 0.003106957534328103\n",
      "336 0.0029665965121239424\n",
      "337 0.0028391953092068434\n",
      "338 0.002716277027502656\n",
      "339 0.0025977150071412325\n",
      "340 0.0024873295333236456\n",
      "341 0.0023795596789568663\n",
      "342 0.002276961924508214\n",
      "343 0.002182470867410302\n",
      "344 0.0020906231366097927\n",
      "345 0.002005152404308319\n",
      "346 0.001921347458846867\n",
      "347 0.0018373235361650586\n",
      "348 0.0017638030694797635\n",
      "349 0.0016884782817214727\n",
      "350 0.0016230185283347964\n",
      "351 0.001556035946123302\n",
      "352 0.0014957545790821314\n",
      "353 0.0014366337563842535\n",
      "354 0.0013773253886029124\n",
      "355 0.001322503318078816\n",
      "356 0.001272672670893371\n",
      "357 0.0012230700813233852\n",
      "358 0.00117888068780303\n",
      "359 0.0011336769675835967\n",
      "360 0.0010883837239816785\n",
      "361 0.001047970145009458\n",
      "362 0.0010095657780766487\n",
      "363 0.0009703239775262773\n",
      "364 0.000934409792535007\n",
      "365 0.0009008931810967624\n",
      "366 0.0008666348876431584\n",
      "367 0.0008359237108379602\n",
      "368 0.000806173775345087\n",
      "369 0.0007774170371703804\n",
      "370 0.0007511680596508086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 0.0007242393912747502\n",
      "372 0.0006989868124946952\n",
      "373 0.0006747244624421\n",
      "374 0.000652264105156064\n",
      "375 0.0006286889547482133\n",
      "376 0.0006075476994737983\n",
      "377 0.000586759124416858\n",
      "378 0.0005687028751708567\n",
      "379 0.0005481916014105082\n",
      "380 0.000531013123691082\n",
      "381 0.0005144558963365853\n",
      "382 0.0004977902281098068\n",
      "383 0.0004815594002138823\n",
      "384 0.0004657046520151198\n",
      "385 0.000450614548753947\n",
      "386 0.00043737521627917886\n",
      "387 0.00042350622243247926\n",
      "388 0.0004101276572328061\n",
      "389 0.000397602649172768\n",
      "390 0.0003863891470246017\n",
      "391 0.00037418658030219376\n",
      "392 0.00036342578823678195\n",
      "393 0.0003519885940477252\n",
      "394 0.00034136418253183365\n",
      "395 0.00033193526905961335\n",
      "396 0.0003231581940781325\n",
      "397 0.00031370166107080877\n",
      "398 0.00030480825807899237\n",
      "399 0.0002955725067295134\n",
      "400 0.00028690704493783414\n",
      "401 0.0002794731699395925\n",
      "402 0.00027169371605850756\n",
      "403 0.00026497666840441525\n",
      "404 0.0002573724777903408\n",
      "405 0.0002506297314539552\n",
      "406 0.0002443937410134822\n",
      "407 0.00023787820828147233\n",
      "408 0.00023223826428875327\n",
      "409 0.00022606085985898972\n",
      "410 0.0002207520738011226\n",
      "411 0.00021430308697745204\n",
      "412 0.00020940903050359339\n",
      "413 0.0002040020772255957\n",
      "414 0.00019864985370077193\n",
      "415 0.0001942336675710976\n",
      "416 0.00018948066281154752\n",
      "417 0.0001847709936555475\n",
      "418 0.00018000596901401877\n",
      "419 0.00017601248691789806\n",
      "420 0.00017183936142828315\n",
      "421 0.00016835016140248626\n",
      "422 0.0001641602284507826\n",
      "423 0.00016041188791859895\n",
      "424 0.0001566739083500579\n",
      "425 0.00015369390894193202\n",
      "426 0.00015011930372565985\n",
      "427 0.00014669913798570633\n",
      "428 0.00014385383110493422\n",
      "429 0.0001405134389642626\n",
      "430 0.00013775049592368305\n",
      "431 0.0001348083169432357\n",
      "432 0.00013173051411285996\n",
      "433 0.0001293401583097875\n",
      "434 0.00012619441258721054\n",
      "435 0.00012362327834125608\n",
      "436 0.0001208462635986507\n",
      "437 0.00011841036030091345\n",
      "438 0.00011656160495476797\n",
      "439 0.00011390462896088138\n",
      "440 0.00011176485713804141\n",
      "441 0.00010977577767334878\n",
      "442 0.00010790333908516914\n",
      "443 0.00010579319496173412\n",
      "444 0.00010379325976828113\n",
      "445 0.00010099053179146722\n",
      "446 9.943312761606649e-05\n",
      "447 9.687481360742822e-05\n",
      "448 9.512998076388612e-05\n",
      "449 9.35400094022043e-05\n",
      "450 9.191310527967289e-05\n",
      "451 9.013942326419055e-05\n",
      "452 8.87949499883689e-05\n",
      "453 8.606044139014557e-05\n",
      "454 8.508231258019805e-05\n",
      "455 8.356217585969716e-05\n",
      "456 8.201946911867708e-05\n",
      "457 8.034131315071136e-05\n",
      "458 7.916369941085577e-05\n",
      "459 7.752619421808049e-05\n",
      "460 7.64668729971163e-05\n",
      "461 7.530750735895708e-05\n",
      "462 7.41973562981002e-05\n",
      "463 7.265456952154636e-05\n",
      "464 7.18093870091252e-05\n",
      "465 7.063608791213483e-05\n",
      "466 6.916702113812789e-05\n",
      "467 6.810540071455762e-05\n",
      "468 6.720352394040674e-05\n",
      "469 6.586761446669698e-05\n",
      "470 6.457402923842892e-05\n",
      "471 6.338131061056629e-05\n",
      "472 6.229680002434179e-05\n",
      "473 6.134901923360303e-05\n",
      "474 6.0671900428133085e-05\n",
      "475 5.966219396214001e-05\n",
      "476 5.8755369536811486e-05\n",
      "477 5.762481305282563e-05\n",
      "478 5.669699748978019e-05\n",
      "479 5.600310396403074e-05\n",
      "480 5.491412593983114e-05\n",
      "481 5.4138006817083806e-05\n",
      "482 5.340829011402093e-05\n",
      "483 5.2611183491535485e-05\n",
      "484 5.188034992897883e-05\n",
      "485 5.1086433813907206e-05\n",
      "486 5.055693327449262e-05\n",
      "487 4.93582192575559e-05\n",
      "488 4.8990226787282154e-05\n",
      "489 4.8035475629149005e-05\n",
      "490 4.73949039587751e-05\n",
      "491 4.650735718314536e-05\n",
      "492 4.6073288103798404e-05\n",
      "493 4.544679541140795e-05\n",
      "494 4.452478242455982e-05\n",
      "495 4.389013338368386e-05\n",
      "496 4.353508120402694e-05\n",
      "497 4.285446266294457e-05\n",
      "498 4.2288498661946505e-05\n",
      "499 4.17956653109286e-05\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "N , D_IN , H , D_OUT = 64 , 1000, 100, 10 # 64个数据，输入时1000维 隐层100维 输出是10维的\n",
    "# 随机创建一些训练数据\n",
    "x = torch.randn(N,D_IN) # x = np.random.randn(N,D_IN)\n",
    "y = torch.randn(N,D_OUT) # y = np.random.randn(N,D_OUT)\n",
    "\n",
    "w1 = torch.randn(D_IN, H, requires_grad = True) # w1 = np.random.randn(D_IN,H)\n",
    "w2 = torch.randn(H, D_OUT, requires_grad = True) # w2 = np.random.randn(H,D_OUT)\n",
    "\n",
    "#搭建神经网络并训练\n",
    "# 使用 nn 来搭建一个神经网络\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_IN,H), # 默认是 y = w* x + b ,这里的 b 可以通过设置进行取消 bias = False\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H,D_OUT)\n",
    ")\n",
    "# 对模型进行初始化，可以提升训练效果\n",
    "#torch.nn.init.normal(model[0].weight) # model[0] 指的是第0层 \n",
    "#torch.nn.init.normal(model[2].weight) # model[2] 指的是第2层 \n",
    "\n",
    "learning_rate = 1e-4 # Adam 的 learning rate 在 1e-3 与 1e-4 之间\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "\n",
    "#learning_rate = 1e-6 # Adam 的 learning rate 在 1e-3 与 1e-4 之间\n",
    "#optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
    "\n",
    "''' 通过比较我们可以知道，当我们使用 Adam 进行有优化的时候，不需要进行 normal 的初始化。\n",
    "    但是当我们使用 GD 或者 SGD 的方式进行优化的时候，就需要使用 normal 来进行初始化。\n",
    "    而且 SGD 与 GD 对应的学习率在 1e-6 左右\n",
    "    Adam 的学习率 在 1e-3 和 1e-4 之间'''\n",
    "\n",
    "\n",
    "# 使用 GPU 来计算\n",
    "# model = model.to_('cuda:0')\n",
    "# model = model.cuda()\n",
    "loss_fn = nn.MSELoss(reduction = 'sum') #这里只是 loss function \n",
    "\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = model(x) # model 会直接 进行 forward pass  即model.forward()\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = loss_fn(y_pred , y) # 这里是一个 compute graph\n",
    "    \n",
    "    print(it,loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backwrad pass\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step() #自动更新优化 model 的参数 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pttorch： 自定义 nn Mudules=s\n",
    "我们可以自定义一个模型，这个模型继承自 nn.Module类。如果需要定义一个比 Sequential 模型更加复杂的模型，需要定义一个 nn.Module 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 654.1214599609375\n",
      "1 637.0352172851562\n",
      "2 620.4612426757812\n",
      "3 604.3917236328125\n",
      "4 588.8212280273438\n",
      "5 573.7405395507812\n",
      "6 559.1384887695312\n",
      "7 544.9327392578125\n",
      "8 531.1913452148438\n",
      "9 517.7940063476562\n",
      "10 504.76611328125\n",
      "11 492.052490234375\n",
      "12 479.7879943847656\n",
      "13 468.01849365234375\n",
      "14 456.622314453125\n",
      "15 445.6759948730469\n",
      "16 435.0380554199219\n",
      "17 424.7362976074219\n",
      "18 414.706298828125\n",
      "19 404.9183349609375\n",
      "20 395.40325927734375\n",
      "21 386.1645812988281\n",
      "22 377.1650390625\n",
      "23 368.37506103515625\n",
      "24 359.78350830078125\n",
      "25 351.3839416503906\n",
      "26 343.1648254394531\n",
      "27 335.1298828125\n",
      "28 327.2994384765625\n",
      "29 319.64599609375\n",
      "30 312.1800231933594\n",
      "31 304.9039611816406\n",
      "32 297.8355407714844\n",
      "33 290.9017639160156\n",
      "34 284.11480712890625\n",
      "35 277.47515869140625\n",
      "36 270.9679870605469\n",
      "37 264.5984802246094\n",
      "38 258.3965148925781\n",
      "39 252.3294677734375\n",
      "40 246.37327575683594\n",
      "41 240.5294647216797\n",
      "42 234.79444885253906\n",
      "43 229.18128967285156\n",
      "44 223.68307495117188\n",
      "45 218.31863403320312\n",
      "46 213.05484008789062\n",
      "47 207.875\n",
      "48 202.79759216308594\n",
      "49 197.81076049804688\n",
      "50 192.90902709960938\n",
      "51 188.1075897216797\n",
      "52 183.4055938720703\n",
      "53 178.79727172851562\n",
      "54 174.2826385498047\n",
      "55 169.86451721191406\n",
      "56 165.532470703125\n",
      "57 161.27932739257812\n",
      "58 157.0954132080078\n",
      "59 152.98403930664062\n",
      "60 148.9567413330078\n",
      "61 145.01113891601562\n",
      "62 141.14926147460938\n",
      "63 137.3560028076172\n",
      "64 133.63111877441406\n",
      "65 129.97830200195312\n",
      "66 126.40870666503906\n",
      "67 122.90617370605469\n",
      "68 119.4661636352539\n",
      "69 116.10665893554688\n",
      "70 112.82591247558594\n",
      "71 109.61454772949219\n",
      "72 106.47130584716797\n",
      "73 103.39525604248047\n",
      "74 100.38980865478516\n",
      "75 97.45372772216797\n",
      "76 94.58905029296875\n",
      "77 91.79410552978516\n",
      "78 89.0621337890625\n",
      "79 86.39534759521484\n",
      "80 83.79698944091797\n",
      "81 81.26155090332031\n",
      "82 78.78535461425781\n",
      "83 76.36557006835938\n",
      "84 74.00484466552734\n",
      "85 71.70128631591797\n",
      "86 69.4564437866211\n",
      "87 67.27197265625\n",
      "88 65.14546966552734\n",
      "89 63.07324981689453\n",
      "90 61.056217193603516\n",
      "91 59.0922966003418\n",
      "92 57.18234634399414\n",
      "93 55.32162094116211\n",
      "94 53.513248443603516\n",
      "95 51.752220153808594\n",
      "96 50.03821563720703\n",
      "97 48.37022018432617\n",
      "98 46.74747085571289\n",
      "99 45.17133712768555\n",
      "100 43.63740921020508\n",
      "101 42.14910125732422\n",
      "102 40.701210021972656\n",
      "103 39.29768753051758\n",
      "104 37.93592071533203\n",
      "105 36.61190414428711\n",
      "106 35.32657241821289\n",
      "107 34.07964324951172\n",
      "108 32.86663055419922\n",
      "109 31.69122886657715\n",
      "110 30.55071449279785\n",
      "111 29.44354820251465\n",
      "112 28.37059211730957\n",
      "113 27.328041076660156\n",
      "114 26.318069458007812\n",
      "115 25.34196662902832\n",
      "116 24.39496421813965\n",
      "117 23.47966766357422\n",
      "118 22.59384536743164\n",
      "119 21.737316131591797\n",
      "120 20.90911102294922\n",
      "121 20.107337951660156\n",
      "122 19.333036422729492\n",
      "123 18.584882736206055\n",
      "124 17.8614444732666\n",
      "125 17.162668228149414\n",
      "126 16.487472534179688\n",
      "127 15.836417198181152\n",
      "128 15.207793235778809\n",
      "129 14.601099014282227\n",
      "130 14.016134262084961\n",
      "131 13.453161239624023\n",
      "132 12.910369873046875\n",
      "133 12.385209083557129\n",
      "134 11.879581451416016\n",
      "135 11.391511917114258\n",
      "136 10.921167373657227\n",
      "137 10.466700553894043\n",
      "138 10.029029846191406\n",
      "139 9.60721206665039\n",
      "140 9.201130867004395\n",
      "141 8.81068229675293\n",
      "142 8.434815406799316\n",
      "143 8.072918891906738\n",
      "144 7.725053787231445\n",
      "145 7.390750408172607\n",
      "146 7.069478511810303\n",
      "147 6.760511875152588\n",
      "148 6.463626861572266\n",
      "149 6.178658485412598\n",
      "150 5.904855728149414\n",
      "151 5.642146587371826\n",
      "152 5.390386581420898\n",
      "153 5.148552417755127\n",
      "154 4.916801929473877\n",
      "155 4.6944580078125\n",
      "156 4.481122016906738\n",
      "157 4.2769317626953125\n",
      "158 4.080808162689209\n",
      "159 3.8929309844970703\n",
      "160 3.71319317817688\n",
      "161 3.541175127029419\n",
      "162 3.3764445781707764\n",
      "163 3.2185771465301514\n",
      "164 3.067653179168701\n",
      "165 2.923496723175049\n",
      "166 2.7854409217834473\n",
      "167 2.653446674346924\n",
      "168 2.5271944999694824\n",
      "169 2.4065637588500977\n",
      "170 2.2912967205047607\n",
      "171 2.1809475421905518\n",
      "172 2.0756382942199707\n",
      "173 1.974998116493225\n",
      "174 1.8788905143737793\n",
      "175 1.7870951890945435\n",
      "176 1.6994472742080688\n",
      "177 1.6157418489456177\n",
      "178 1.5360349416732788\n",
      "179 1.460103988647461\n",
      "180 1.3876124620437622\n",
      "181 1.3184266090393066\n",
      "182 1.2525932788848877\n",
      "183 1.1897895336151123\n",
      "184 1.1299091577529907\n",
      "185 1.0728918313980103\n",
      "186 1.0185353755950928\n",
      "187 0.9668031930923462\n",
      "188 0.917574942111969\n",
      "189 0.870655357837677\n",
      "190 0.8259893655776978\n",
      "191 0.783487856388092\n",
      "192 0.7430739402770996\n",
      "193 0.7045960426330566\n",
      "194 0.6679881811141968\n",
      "195 0.633175790309906\n",
      "196 0.6000863909721375\n",
      "197 0.5686379075050354\n",
      "198 0.53872150182724\n",
      "199 0.51031094789505\n",
      "200 0.48330989480018616\n",
      "201 0.4576222598552704\n",
      "202 0.43325358629226685\n",
      "203 0.4101048707962036\n",
      "204 0.38811343908309937\n",
      "205 0.36723971366882324\n",
      "206 0.3474174737930298\n",
      "207 0.32860302925109863\n",
      "208 0.31074684858322144\n",
      "209 0.2938101887702942\n",
      "210 0.2777164578437805\n",
      "211 0.26247739791870117\n",
      "212 0.24805240333080292\n",
      "213 0.2343629151582718\n",
      "214 0.2213880568742752\n",
      "215 0.20910212397575378\n",
      "216 0.1974555104970932\n",
      "217 0.1864331066608429\n",
      "218 0.17599576711654663\n",
      "219 0.16607308387756348\n",
      "220 0.15667401254177094\n",
      "221 0.14775563776493073\n",
      "222 0.13929662108421326\n",
      "223 0.13126930594444275\n",
      "224 0.12365815043449402\n",
      "225 0.11645045876502991\n",
      "226 0.10963170975446701\n",
      "227 0.10317472368478775\n",
      "228 0.09707227349281311\n",
      "229 0.09130814671516418\n",
      "230 0.08585954457521439\n",
      "231 0.0807177796959877\n",
      "232 0.07586166262626648\n",
      "233 0.07128031551837921\n",
      "234 0.06695915013551712\n",
      "235 0.06288958340883255\n",
      "236 0.059045713394880295\n",
      "237 0.05543181672692299\n",
      "238 0.05202794075012207\n",
      "239 0.048821378499269485\n",
      "240 0.045803606510162354\n",
      "241 0.0429629348218441\n",
      "242 0.040292687714099884\n",
      "243 0.0377841480076313\n",
      "244 0.03542598709464073\n",
      "245 0.03320939466357231\n",
      "246 0.0311274416744709\n",
      "247 0.029171889647841454\n",
      "248 0.02733485773205757\n",
      "249 0.025610754266381264\n",
      "250 0.0239909328520298\n",
      "251 0.022471493110060692\n",
      "252 0.021045595407485962\n",
      "253 0.01970774680376053\n",
      "254 0.018452975898981094\n",
      "255 0.017276134341955185\n",
      "256 0.01617223396897316\n",
      "257 0.015137692913413048\n",
      "258 0.014168063178658485\n",
      "259 0.01325880829244852\n",
      "260 0.012407091446220875\n",
      "261 0.011608266271650791\n",
      "262 0.010860105976462364\n",
      "263 0.010159227065742016\n",
      "264 0.009502495639026165\n",
      "265 0.008887642063200474\n",
      "266 0.008311559446156025\n",
      "267 0.0077721960842609406\n",
      "268 0.0072674257680773735\n",
      "269 0.00679443683475256\n",
      "270 0.006351777818053961\n",
      "271 0.005938128102570772\n",
      "272 0.005551254376769066\n",
      "273 0.00518912123516202\n",
      "274 0.0048502660356462\n",
      "275 0.004533195868134499\n",
      "276 0.004236394539475441\n",
      "277 0.003958777524530888\n",
      "278 0.003699030727148056\n",
      "279 0.003455980448052287\n",
      "280 0.0032286918722093105\n",
      "281 0.00301600550301373\n",
      "282 0.0028171096928417683\n",
      "283 0.002631167648360133\n",
      "284 0.0024571618996560574\n",
      "285 0.00229451572522521\n",
      "286 0.002142407698556781\n",
      "287 0.0020001933444291353\n",
      "288 0.0018672248115763068\n",
      "289 0.00174287473782897\n",
      "290 0.0016267142491415143\n",
      "291 0.0015180474147200584\n",
      "292 0.001416556304320693\n",
      "293 0.0013216730440035462\n",
      "294 0.0012330772588029504\n",
      "295 0.0011502362322062254\n",
      "296 0.0010728558991104364\n",
      "297 0.0010005608201026917\n",
      "298 0.000933078583329916\n",
      "299 0.0008700531325303018\n",
      "300 0.0008111225324682891\n",
      "301 0.0007561726961284876\n",
      "302 0.0007048717234283686\n",
      "303 0.0006569619872607291\n",
      "304 0.0006122347549535334\n",
      "305 0.000570483214687556\n",
      "306 0.0005315269809216261\n",
      "307 0.0004951658193022013\n",
      "308 0.00046123904758132994\n",
      "309 0.00042961433064192533\n",
      "310 0.00040010089287534356\n",
      "311 0.0003725541173480451\n",
      "312 0.00034688785672187805\n",
      "313 0.00032293767435476184\n",
      "314 0.0003005896869581193\n",
      "315 0.00027977803256362677\n",
      "316 0.0002603645552881062\n",
      "317 0.0002422656398266554\n",
      "318 0.0002253988932352513\n",
      "319 0.00020968730677850544\n",
      "320 0.0001950363366631791\n",
      "321 0.0001813962880987674\n",
      "322 0.00016868283273652196\n",
      "323 0.00015684125537518412\n",
      "324 0.00014580746938008815\n",
      "325 0.00013553813914768398\n",
      "326 0.0001259784767171368\n",
      "327 0.00011707034718710929\n",
      "328 0.00010878290777327493\n",
      "329 0.0001010741907521151\n",
      "330 9.388988837599754e-05\n",
      "331 8.720418554730713e-05\n",
      "332 8.098500256892294e-05\n",
      "333 7.520325743826106e-05\n",
      "334 6.982240302022547e-05\n",
      "335 6.481886521214619e-05\n",
      "336 6.0166086768731475e-05\n",
      "337 5.583992606261745e-05\n",
      "338 5.1814145990647376e-05\n",
      "339 4.807304503628984e-05\n",
      "340 4.4595333747565746e-05\n",
      "341 4.136747884331271e-05\n",
      "342 3.836553878500126e-05\n",
      "343 3.557474337867461e-05\n",
      "344 3.298399315099232e-05\n",
      "345 3.057491630897857e-05\n",
      "346 2.8341244615148753e-05\n",
      "347 2.626643436087761e-05\n",
      "348 2.4338220100617036e-05\n",
      "349 2.254791252198629e-05\n",
      "350 2.0889652660116553e-05\n",
      "351 1.934927422553301e-05\n",
      "352 1.7917876903084107e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353 1.659201006987132e-05\n",
      "354 1.5358995369751938e-05\n",
      "355 1.4218112482922152e-05\n",
      "356 1.31590177261387e-05\n",
      "357 1.2177442840766162e-05\n",
      "358 1.1265841749263927e-05\n",
      "359 1.042340591084212e-05\n",
      "360 9.640795724408235e-06\n",
      "361 8.91568106453633e-06\n",
      "362 8.245240678661503e-06\n",
      "363 7.622378689120524e-06\n",
      "364 7.045795427984558e-06\n",
      "365 6.511837455036584e-06\n",
      "366 6.017488885845523e-06\n",
      "367 5.559593773796223e-06\n",
      "368 5.13656004841323e-06\n",
      "369 4.743611498270184e-06\n",
      "370 4.380435711937025e-06\n",
      "371 4.04431148126605e-06\n",
      "372 3.7337877074605785e-06\n",
      "373 3.446306664045551e-06\n",
      "374 3.1811439384910045e-06\n",
      "375 2.93560151476413e-06\n",
      "376 2.7077776394435205e-06\n",
      "377 2.4980015496112173e-06\n",
      "378 2.3036238872009562e-06\n",
      "379 2.1243236005830113e-06\n",
      "380 1.958789653144777e-06\n",
      "381 1.8056764474749798e-06\n",
      "382 1.6636812461001682e-06\n",
      "383 1.5333076817114488e-06\n",
      "384 1.4127970189292682e-06\n",
      "385 1.3015263675697497e-06\n",
      "386 1.1986941217401181e-06\n",
      "387 1.1043530321330763e-06\n",
      "388 1.01648095096607e-06\n",
      "389 9.35533194024174e-07\n",
      "390 8.610781492279784e-07\n",
      "391 7.924709279905073e-07\n",
      "392 7.288415417860961e-07\n",
      "393 6.705795954076166e-07\n",
      "394 6.169735229377693e-07\n",
      "395 5.670062819262967e-07\n",
      "396 5.218664682615781e-07\n",
      "397 4.794916890205059e-07\n",
      "398 4.407387734772783e-07\n",
      "399 4.0480122720509826e-07\n",
      "400 3.7200979363660736e-07\n",
      "401 3.417914626879792e-07\n",
      "402 3.1409865641762735e-07\n",
      "403 2.88363423806004e-07\n",
      "404 2.647590520155063e-07\n",
      "405 2.4305091983478633e-07\n",
      "406 2.229132149977886e-07\n",
      "407 2.0462611871607805e-07\n",
      "408 1.8798802159381012e-07\n",
      "409 1.724075815445758e-07\n",
      "410 1.5815760434634285e-07\n",
      "411 1.4495877564968396e-07\n",
      "412 1.328730547811574e-07\n",
      "413 1.218348160136884e-07\n",
      "414 1.117174690534739e-07\n",
      "415 1.0231703839735928e-07\n",
      "416 9.365552955387102e-08\n",
      "417 8.581405808172349e-08\n",
      "418 7.851065930708501e-08\n",
      "419 7.195649232016876e-08\n",
      "420 6.595521995222953e-08\n",
      "421 6.022492726742712e-08\n",
      "422 5.5139622645583586e-08\n",
      "423 5.0449063593305254e-08\n",
      "424 4.6268642250879566e-08\n",
      "425 4.2294164614986585e-08\n",
      "426 3.869006448553591e-08\n",
      "427 3.544523607956762e-08\n",
      "428 3.2298039798206446e-08\n",
      "429 2.9618210106718834e-08\n",
      "430 2.6990589319098035e-08\n",
      "431 2.4677333954059577e-08\n",
      "432 2.2603149574251802e-08\n",
      "433 2.0671413025752372e-08\n",
      "434 1.8847694960300032e-08\n",
      "435 1.7243209526895953e-08\n",
      "436 1.5785458273853692e-08\n",
      "437 1.4431377870494089e-08\n",
      "438 1.3184436653546072e-08\n",
      "439 1.1994382376201429e-08\n",
      "440 1.093297896659351e-08\n",
      "441 1.0053819998745439e-08\n",
      "442 9.187892224815641e-09\n",
      "443 8.396074946404042e-09\n",
      "444 7.644683108765093e-09\n",
      "445 7.013838398961525e-09\n",
      "446 6.424700327301025e-09\n",
      "447 5.853735274286009e-09\n",
      "448 5.394839686090336e-09\n",
      "449 4.905675865529702e-09\n",
      "450 4.505957384992598e-09\n",
      "451 4.137113318591901e-09\n",
      "452 3.75266928642759e-09\n",
      "453 3.45753803365767e-09\n",
      "454 3.1784730403217054e-09\n",
      "455 2.9184454852781982e-09\n",
      "456 2.672632115618967e-09\n",
      "457 2.429104473122834e-09\n",
      "458 2.24385399150151e-09\n",
      "459 2.0607160422514426e-09\n",
      "460 1.901788282410166e-09\n",
      "461 1.7513730465879007e-09\n",
      "462 1.6077142950265966e-09\n",
      "463 1.4904204537202759e-09\n",
      "464 1.3601223480819158e-09\n",
      "465 1.2556882200698283e-09\n",
      "466 1.155068374281143e-09\n",
      "467 1.0764061864065866e-09\n",
      "468 1.006473238085448e-09\n",
      "469 9.203370843202663e-10\n",
      "470 8.572129672757001e-10\n",
      "471 7.939550128455153e-10\n",
      "472 7.450361438898767e-10\n",
      "473 7.04888536429138e-10\n",
      "474 6.411825514973657e-10\n",
      "475 6.068454627694564e-10\n",
      "476 5.646574874340615e-10\n",
      "477 5.320031082334253e-10\n",
      "478 5.014609838482897e-10\n",
      "479 4.690179911115422e-10\n",
      "480 4.450135815403655e-10\n",
      "481 4.15502687811653e-10\n",
      "482 3.870491982471691e-10\n",
      "483 3.7039404876537674e-10\n",
      "484 3.49006185063061e-10\n",
      "485 3.3214964112460166e-10\n",
      "486 3.1658267674039564e-10\n",
      "487 3.046489727154267e-10\n",
      "488 2.9011038016335533e-10\n",
      "489 2.754224626144719e-10\n",
      "490 2.629066964132676e-10\n",
      "491 2.50686360558916e-10\n",
      "492 2.41454412019948e-10\n",
      "493 2.32081867612699e-10\n",
      "494 2.2561177925872755e-10\n",
      "495 2.1239901504266356e-10\n",
      "496 2.0522107624376673e-10\n",
      "497 1.9707067921981292e-10\n",
      "498 1.8963949854899909e-10\n",
      "499 1.8691069525456072e-10\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "N , D_IN , H , D_OUT = 64 , 1000, 100, 10 # 64个数据，输入时1000维 隐层100维 输出是10维的\n",
    "# 随机创建一些训练数据\n",
    "x = torch.randn(N,D_IN) # x = np.random.randn(N,D_IN)\n",
    "y = torch.randn(N,D_OUT) # y = np.random.randn(N,D_OUT)\n",
    "\n",
    "w1 = torch.randn(D_IN, H, requires_grad = True) # w1 = np.random.randn(D_IN,H)\n",
    "w2 = torch.randn(H, D_OUT, requires_grad = True) # w2 = np.random.randn(H,D_OUT)\n",
    "\n",
    "#搭建神经网络并训练\n",
    "# 使用 nn 来搭建一个神经网络\n",
    "class TwoLayersNet(torch.nn.Module):\n",
    "    def __init__(self, D_IN, H, D_OUT):\n",
    "        super(TwoLayersNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_IN, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_OUT)\n",
    "    def forward(self,x):\n",
    "        y_pred = self.linear2(self.linear1(x).clamp(min=0))\n",
    "        return y_pred\n",
    "\n",
    "model = TwoLayersNet(D_IN, H, D_OUT)\n",
    "\n",
    "learning_rate = 1e-4 # Adam 的 learning rate 在 1e-3 与 1e-4 之间\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction = 'sum') #这里只是 loss function \n",
    "\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = model(x) # model 会直接 进行 forward pass  即model.forward()\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = loss_fn(y_pred , y) # 这里是一个 compute graph\n",
    "    print(it,loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backwrad pass\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step() #自动更新优化 model 的参数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
